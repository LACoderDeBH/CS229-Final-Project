{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and plot dataset\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas import concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    " \n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transform Time Series to Stationary\\nThe Shampoo Sales dataset is not stationary.\\n\\nThis means that there is a structure in the data that is dependent on the time. Specifically, there is an increasing trend in the data.\\n\\nStationary data is easier to model and will very likely result in more skillful forecasts.\\n\\nThe trend can be removed from the observations, then added back to forecasts later to return the prediction to the original scale and calculate a comparable error score.\\n\\nA standard way to remove a trend is by differencing the data. That is the observation from the previous time step (t-1) is subtracted from the current observation (t). \\nThis removes the trend and we are left with a difference series, or the changes to the observations from one time step to the next.\\n\\nWe can achieve this automatically using the diff() function in pandas. \\nAlternatively, we can get finer grained control and write our own function to do this, \\nwhich is preferred for its flexibility in this case.\\n\\nBelow is a function called difference() that calculates a differenced series. \\nNote that the first observation in the series is skipped as there is no prior observation \\nwith which to calculate a differenced value.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Transform Time Series to Stationary\n",
    "The Shampoo Sales dataset is not stationary.\n",
    "\n",
    "This means that there is a structure in the data that is dependent on the time. Specifically, there is an increasing trend in the data.\n",
    "\n",
    "Stationary data is easier to model and will very likely result in more skillful forecasts.\n",
    "\n",
    "The trend can be removed from the observations, then added back to forecasts later to return the prediction to the original scale and calculate a comparable error score.\n",
    "\n",
    "A standard way to remove a trend is by differencing the data. That is the observation from the previous time step (t-1) is subtracted from the current observation (t). \n",
    "This removes the trend and we are left with a difference series, or the changes to the observations from one time step to the next.\n",
    "\n",
    "We can achieve this automatically using the diff() function in pandas. \n",
    "Alternatively, we can get finer grained control and write our own function to do this, \n",
    "which is preferred for its flexibility in this case.\n",
    "\n",
    "Below is a function called difference() that calculates a differenced series. \n",
    "Note that the first observation in the series is skipped as there is no prior observation \n",
    "with which to calculate a differenced value.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We also need to invert this process in order to take forecasts made on the differenced series back into their original scale.\\n\\nThe function below, called inverse_difference(), inverts this operation.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We also need to invert this process in order to take forecasts made on the differenced series back into their original scale.\n",
    "\n",
    "The function below, called inverse_difference(), inverts this operation.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We can test out these functions by differencing the whole series, then returning it to the original scale, as follows'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We can test out these functions by differencing the whole series, then returning it to the original scale, as follows'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "1901-01-01    266.0\n",
      "1901-02-01    145.9\n",
      "1901-03-01    183.1\n",
      "1901-04-01    119.3\n",
      "1901-05-01    180.3\n",
      "Name: Sales, dtype: float64\n",
      "0   -120.1\n",
      "1     37.2\n",
      "2    -63.8\n",
      "3     61.0\n",
      "4    -11.8\n",
      "dtype: float64\n",
      "0    145.9\n",
      "1    183.1\n",
      "2    119.3\n",
      "3    180.3\n",
      "4    168.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from pandas import Series\n",
    " \n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    " \n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    " \n",
    "# load dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "print(series.head())\n",
    "# transform to be stationary\n",
    "differenced = difference(series, 1)\n",
    "print(differenced.head())\n",
    "# invert transform\n",
    "inverted = list()\n",
    "for i in range(len(differenced)):\n",
    "\tvalue = inverse_difference(series, differenced[i], len(series)-i)\n",
    "\tinverted.append(value)\n",
    "inverted = Series(inverted)\n",
    "print(inverted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRunning the example prints the first 5 rows of the loaded data, then the first 5 rows of the differenced series, then finally the first 5 rows with the difference operation inverted.\\n\\nNote that the first observation in the original dataset was removed from the inverted difference data. Besides that, the last set of data matches the first as expected.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Running the example prints the first 5 rows of the loaded data, then the first 5 rows of the differenced series, then finally the first 5 rows with the difference operation inverted.\n",
    "\n",
    "Note that the first observation in the original dataset was removed from the inverted difference data. Besides that, the last set of data matches the first as expected.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "'''\n",
    "Transform Time Series to Scale\n",
    "Like other neural networks, LSTMs expect data to be within the scale of the activation function used by the network.\n",
    "\n",
    "The default activation function for LSTMs is the hyperbolic tangent (tanh), which outputs values between -1 and 1. This is the preferred range for the time series data.\n",
    "\n",
    "To make the experiment fair, the scaling coefficients (min and max) values must be calculated on the training dataset and applied to scale the test dataset and any forecasts. This is to avoid contaminating the experiment with knowledge from the test dataset, which might give the model a small edge.\n",
    "\n",
    "We can transform the dataset to the range [-1, 1] using the MinMaxScaler class. Like other scikit-learn transform classes, it requires data provided in a matrix format with rows and columns. Therefore, we must reshape our NumPy arrays before transforming.\n",
    "\n",
    "For example:\n",
    "'''\n",
    "#transform scale\n",
    "X = series.values\n",
    "X = X.reshape(len(X), 1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(X)\n",
    "scaled_X = scaler.transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Again, we must invert the scale on forecasts to return the values back to the original \n",
    "scale so that the results can be interpreted and a comparable error score can be calculated.\n",
    "'''# invert transform\n",
    "inverted_X = scaler.inverse_transform(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "1901-01-01    266.0\n",
      "1901-02-01    145.9\n",
      "1901-03-01    183.1\n",
      "1901-04-01    119.3\n",
      "1901-05-01    180.3\n",
      "Name: Sales, dtype: float64\n",
      "0   -0.478585\n",
      "1   -0.905456\n",
      "2   -0.773236\n",
      "3   -1.000000\n",
      "4   -0.783188\n",
      "dtype: float64\n",
      "0    266.0\n",
      "1    145.9\n",
      "2    183.1\n",
      "3    119.3\n",
      "4    180.3\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "print(series.head())\n",
    "# transform scale\n",
    "X = series.values\n",
    "X = X.reshape(len(X), 1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(X)\n",
    "scaled_X = scaler.transform(X)\n",
    "scaled_series = Series(scaled_X[:, 0])\n",
    "print(scaled_series.head())\n",
    "# invert transform\n",
    "inverted_X = scaler.inverse_transform(scaled_X)\n",
    "inverted_series = Series(inverted_X[:, 0])\n",
    "print(inverted_series.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLSTM Model Development\\nThe Long Short-Term Memory network (LSTM) is a type of Recurrent Neural Network (RNN).\\n\\nA benefit of this type of network is that it can learn and remember over long sequences and does not rely on a pre-specified window lagged observation as input.\\n\\nIn Keras, this is referred to as stateful, and involves setting the “stateful” argument to “True” when defining an LSTM layer.\\n\\nBy default, an LSTM layer in Keras maintains state between data within one batch. A batch of data is a fixed-sized number of rows from the training dataset that defines how many patterns to process before updating the weights of the network. State in the LSTM layer between batches is cleared by default, therefore we must make the LSTM stateful. This gives us fine-grained control over when state of the LSTM layer is cleared, by calling the reset_states() function.\\n\\nThe LSTM layer expects input to be in a matrix with the dimensions: [samples, time steps, features].\\n\\nSamples: These are independent observations from the domain, typically rows of data.\\nTime steps: These are separate time steps of a given variable for a given observation.\\nFeatures: These are separate measures observed at the time of observation.\\nWe have some flexibility in how the Shampoo Sales dataset is framed for the network. We will keep it simple and frame the problem as each time step in the original sequence is one separate sample, with one timestep and one feature.\\n\\nGiven that the training dataset is defined as X inputs and y outputs, it must be reshaped into the Samples/TimeSteps/Features format, for example:\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "LSTM Model Development\n",
    "The Long Short-Term Memory network (LSTM) is a type of Recurrent Neural Network (RNN).\n",
    "\n",
    "A benefit of this type of network is that it can learn and remember over long sequences and does not rely on a pre-specified window lagged observation as input.\n",
    "\n",
    "In Keras, this is referred to as stateful, and involves setting the “stateful” argument to “True” when defining an LSTM layer.\n",
    "\n",
    "By default, an LSTM layer in Keras maintains state between data within one batch. A batch of data is a fixed-sized number of rows from the training dataset that defines how many patterns to process before updating the weights of the network. State in the LSTM layer between batches is cleared by default, therefore we must make the LSTM stateful. This gives us fine-grained control over when state of the LSTM layer is cleared, by calling the reset_states() function.\n",
    "\n",
    "The LSTM layer expects input to be in a matrix with the dimensions: [samples, time steps, features].\n",
    "\n",
    "Samples: These are independent observations from the domain, typically rows of data.\n",
    "Time steps: These are separate time steps of a given variable for a given observation.\n",
    "Features: These are separate measures observed at the time of observation.\n",
    "We have some flexibility in how the Shampoo Sales dataset is framed for the network. We will keep it simple and frame the problem as each time step in the original sequence is one separate sample, with one timestep and one feature.\n",
    "\n",
    "Given that the training dataset is defined as X inputs and y outputs, it must be reshaped into the Samples/TimeSteps/Features format, for example:\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Complete LSTM Example\n",
    "\n",
    "In this section, we will fit an LSTM to the Shampoo Sales dataset and evaluate the model.\n",
    "\n",
    "This will involve drawing together all of the elements from the prior sections. There are a lot of them, so let’s review:\n",
    "\n",
    "Load the dataset from CSV file.\n",
    "Transform the dataset to make it suitable for the LSTM model, including:\n",
    "Transforming the data to a supervised learning problem.\n",
    "Transforming the data to be stationary.\n",
    "Transforming the data so that it has the scale -1 to 1.\n",
    "Fitting a stateful LSTM network model to the training data.\n",
    "Evaluating the static LSTM model on the test data.\n",
    "Report the performance of the forecasts.\n",
    "Some things to note about the example:\n",
    "\n",
    "The scaling and inverse scaling behaviors have been moved to the functions scale() and invert_scale() for brevity.\n",
    "The test data is scaled using the fit of the scaler on the training data, as is required to ensure the min/max values of the test data do not influence the model.\n",
    "The order of data transforms was adjusted for convenience to first make the data stationary, then a supervised learning problem, then scaled.\n",
    "Differencing was performed on the entire dataset prior to splitting into train and test sets for convenience. We could just as easily collect observations during the walk-forward validation and difference them as we go. I decided against it for readability.\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Month=1, Predicted=284.766911, Expected=339.700000\n",
      "Month=2, Predicted=332.498228, Expected=440.400000\n",
      "Month=3, Predicted=223.436378, Expected=315.900000\n",
      "Month=4, Predicted=317.755415, Expected=439.300000\n",
      "Month=5, Predicted=265.017656, Expected=401.300000\n",
      "Month=6, Predicted=383.023877, Expected=437.400000\n",
      "Month=7, Predicted=324.190828, Expected=575.500000\n",
      "Month=8, Predicted=167.016270, Expected=407.600000\n",
      "Month=9, Predicted=335.472860, Expected=682.000000\n",
      "Month=10, Predicted=183.561528, Expected=475.300000\n",
      "Month=11, Predicted=386.331328, Expected=581.300000\n",
      "Month=12, Predicted=288.594882, Expected=646.900000\n",
      "Test RMSE: 214.503\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "# load dataset\n",
    "series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "\n",
    "# transform data to be stationary\n",
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "train, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=1)\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "\t# make one-step forecast\n",
    "\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t# invert scaling\n",
    "\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t# invert differencing\n",
    "\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t# store forecast\n",
    "\tpredictions.append(yhat)\n",
    "\texpected = raw_values[len(train) + i + 1]\n",
    "\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-12:])\n",
    "pyplot.plot(predictions)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [name_common, age, mlb_ID, player_ID, year_ID, team_ID, stint_ID, lg_ID, PA, G, Inn, runs_bat, runs_br, runs_dp, runs_field, runs_infield, runs_outfield, runs_catcher, runs_good_plays, runs_defense, runs_position, runs_position_p, runs_replacement, runs_above_rep, runs_above_avg, runs_above_avg_off, runs_above_avg_def, WAA, WAA_off, WAA_def, WAR, WAR_def, WAR_off, WAR_rep, salary, pitcher, teamRpG, oppRpG, oppRpPA_rep, oppRpG_rep, pyth_exponent, pyth_exponent_rep, waa_win_perc, waa_win_perc_off, waa_win_perc_def, waa_win_perc_rep, OPS_plus, TOB_lg, TB_lg]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y')\n",
    "\n",
    "batting_data_path = 'bsb_ref.csv'\n",
    "# INFO:\n",
    "# 101,332 Players with up to 20 features each (exluding year, including team)\n",
    "# if metric not reported for player, set to 0.0 by default\n",
    "\n",
    "df = pd.read_csv(batting_data_path)\n",
    "df = df.fillna(0)\n",
    "\n",
    "# focusing on players after 1975\n",
    "df_recent_players = df[df.year_ID >= 1975] #48k players\n",
    "'''\n",
    "df_recent_players = df_recent_players[['year_ID', 'name_common', 'age', 'mlb_ID', 'player_ID', 'team_ID', 'stint_ID',\n",
    "                                       'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "\n",
    "'''\n",
    "print(df_recent_players.head(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%Y')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54579, 49)\n",
      "2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only list-like objects are allowed to be passed to isin(), you passed a [str]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-da4df7b9639b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mdf_recent_players\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_recent_players\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_recent_players\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_common'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'David Aardsma'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;31m#df.loc[df['column_name'] == some_value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   4509\u001b[0m         \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0manimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4510\u001b[0m         \"\"\"\n\u001b[0;32m-> 4511\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(comps, values)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;34m\"only list-like objects are allowed to be passed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \" to isin(), you passed a [{values_type}]\".format(\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0mvalues_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             )\n\u001b[1;32m    440\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: only list-like objects are allowed to be passed to isin(), you passed a [str]"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y')\n",
    "\n",
    "\n",
    "import csv\n",
    "#players = read_csv('bsb_ref.csv', parse_dates=[4], index_col=0,squeeze=True, date_parser=parser)\n",
    "players = read_csv('bsb_ref.csv', parse_dates=[4], squeeze=True, date_parser=parser)\n",
    "#series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], , squeeze=True, date_parser=parser)\n",
    "\n",
    "# summarize first few rows\n",
    "\n",
    "#original has \n",
    "'''\n",
    "print(players.shape) (107211, 48)\n",
    "print(players.ndim) 2\n",
    "'''\n",
    "\n",
    "players = players.fillna(0)\n",
    "\n",
    "# focusing on players after 1975\n",
    "d1 = '1975-01-01'\n",
    "date = datetime.strptime(d1, '%Y-%m-%d')\n",
    "\n",
    "df_recent_players = players[players.year_ID >= date] #48k players\n",
    "print(df_recent_players.shape) #(54579, 48)\n",
    "print(df_recent_players.ndim) #2\n",
    "\n",
    "#reorder columns so date is first\n",
    "df_recent_players = df_recent_players[['year_ID', 'name_common', 'age', 'mlb_ID', 'player_ID', 'team_ID', 'stint_ID',\n",
    "                                       'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "                                       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_recent_players = df_recent_players.loc[df_recent_players['name_common'] == 'David Aardsma']\n",
    "#df.loc[df['column_name'] == some_value]\n",
    "\n",
    "print(df_recent_players.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  ]\n",
      " [-0.04]\n",
      " [ 0.  ]\n",
      " [-0.02]\n",
      " [ 0.  ]\n",
      " [ 0.  ]\n",
      " [ 0.  ]\n",
      " [ 0.  ]\n",
      " [-0.01]]\n",
      "[ 0.   -0.04  0.   -0.02  0.    0.    0.    0.   -0.01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "#cast all to same type float\n",
    "\n",
    "\n",
    "\n",
    "davidAardsmaDf = df_recent_players.head(9)\n",
    "#print(davidAardsmaDf.head(0))\n",
    "print(davidAardsmaDf.head(1))\n",
    "\n",
    "\n",
    "davidAardsmaDf['G'] = davidAardsmaDf['G'].astype(float)\n",
    "davidAardsmaDf['stint_ID'] = davidAardsmaDf['stint_ID'].astype(float)\n",
    "davidAardsmaDf = davidAardsmaDf.drop([\"team_ID\", \"lg_ID\", \"pitcher\", \"player_ID\", \"name_common\"], axis=1)\n",
    "\n",
    "print(davidAardsmaDf.dtypes, davidAardsmaDf)\n",
    "\n",
    "smallDF = davidAardsmaDf\n",
    "# line plot\n",
    "\n",
    "#print(series)\n",
    "\n",
    "# delete columns using the columns parameter of drop\n",
    "#davidAardsmaDf = davidAardsmaDf.drop(columns=\"name_common\")\n",
    "\n",
    "# Delete multiple columns from the dataframe\"\n",
    "#davidAardsmaDf = davidAardsmaDf.drop([\"team_ID\", \"lg_ID\", \"pitcher\", \"player_ID\", \"name_common\"], axis=1)\n",
    "\n",
    "#print(davidAardsmaDf)\n",
    "\n",
    "\n",
    "smallDF = smallDF.drop(['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg'], axis=1)\n",
    "\n",
    "print(smallDF)\n",
    "# transform data to be stationary\n",
    "\n",
    "raw_values = smallDF.values\n",
    "#s_values = series.values\n",
    "\n",
    "oneDim = np.stack(raw_values, axis =1)\n",
    "#print(raw_values)\n",
    "\n",
    "raw_values = oneDim[0]\n",
    "#print(raw_values)\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "print(\"supervised_values: \", len(supervised_values), supervised_values)\n",
    "train, test = supervised_values[0:-4], supervised_values[-4:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=1)\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "\t# make one-step forecast\n",
    "\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t# invert scaling\n",
    "\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t# invert differencing\n",
    "\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t# store forecast\n",
    "\tpredictions.append(yhat)\n",
    "\texpected = raw_values[len(train) + i + 1]\n",
    "\tprint('Year=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-4:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-4:])\n",
    "pyplot.plot(predictions)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised_values:  8 [[ 0.   -0.04]\n",
      " [-0.04  0.04]\n",
      " [ 0.04 -0.02]\n",
      " [-0.02  0.02]\n",
      " [ 0.02  0.  ]\n",
      " [ 0.    0.  ]\n",
      " [ 0.    0.  ]\n",
      " [ 0.   -0.01]]\n",
      "Year=1, Predicted=-0.032677, Expected=0.000000\n",
      "Year=2, Predicted=-0.018567, Expected=0.000000\n",
      "Year=3, Predicted=-0.022262, Expected=0.000000\n",
      "Year=4, Predicted=-0.020541, Expected=-0.010000\n",
      "Test RMSE: 0.022\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "#cast all to same type float\n",
    "\n",
    "\n",
    "#print(df_recent_players.head(9))\n",
    "davidAardsmaDf = df_recent_players.head(9)\n",
    "#print(davidAardsmaDf.head(0))\n",
    "print(davidAardsmaDf.head(1))\n",
    "\n",
    "\n",
    "davidAardsmaDf['G'] = davidAardsmaDf['G'].astype(float)\n",
    "davidAardsmaDf['stint_ID'] = davidAardsmaDf['stint_ID'].astype(float)\n",
    "davidAardsmaDf = davidAardsmaDf.drop([\"team_ID\", \"lg_ID\", \"pitcher\", \"player_ID\", \"name_common\"], axis=1)\n",
    "\n",
    "print(davidAardsmaDf.dtypes, davidAardsmaDf)\n",
    "\n",
    "smallDF = davidAardsmaDf\n",
    "# line plot\n",
    "\n",
    "#print(series)\n",
    "\n",
    "# delete columns using the columns parameter of drop\n",
    "#davidAardsmaDf = davidAardsmaDf.drop(columns=\"name_common\")\n",
    "\n",
    "# Delete multiple columns from the dataframe\"\n",
    "#davidAardsmaDf = davidAardsmaDf.drop([\"team_ID\", \"lg_ID\", \"pitcher\", \"player_ID\", \"name_common\"], axis=1)\n",
    "\n",
    "#print(davidAardsmaDf)\n",
    "\n",
    "\n",
    "smallDF = smallDF.drop(['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg'], axis=1)\n",
    "\n",
    "print(smallDF)\n",
    "# transform data to be stationary\n",
    "\n",
    "raw_values = smallDF.values\n",
    "#s_values = series.values\n",
    "\n",
    "oneDim = np.stack(raw_values, axis =1)\n",
    "#print(raw_values)\n",
    "\n",
    "raw_values = oneDim[0]\n",
    "#print(raw_values)\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "print(\"supervised_values: \", len(supervised_values), supervised_values)\n",
    "train, test = supervised_values[0:-4], supervised_values[-4:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=1)\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "\t# make one-step forecast\n",
    "\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t# invert scaling\n",
    "\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t# invert differencing\n",
    "\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t# store forecast\n",
    "\tpredictions.append(yhat)\n",
    "\texpected = raw_values[len(train) + i + 1]\n",
    "\tprint('Year=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-4:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-4:])\n",
    "pyplot.plot(predictions)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
