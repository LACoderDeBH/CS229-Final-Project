{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# load and plot dataset\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from pandas import concat\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Complete LSTM Example\n",
    "\n",
    "Load the dataset from CSV file.\n",
    "Transform the dataset to make it suitable for the LSTM model, including:\n",
    "Transforming the data to a supervised learning problem.\n",
    "Transforming the data to be stationary.\n",
    "Transforming the data so that it has the scale -1 to 1.\n",
    "Fitting a stateful LSTM network model to the training data.\n",
    "Evaluating the static LSTM model on the test data.\n",
    "Report the performance of the forecasts.\n",
    "Some things to note about the example:\n",
    "\n",
    "The scaling and inverse scaling behaviors have been moved to the functions scale() and invert_scale() for brevity.\n",
    "The test data is scaled using the fit of the scaler on the training data, as is required to ensure the min/max values of the test data do not influence the model.\n",
    "The order of data transforms was adjusted for convenience to first make the data stationary, then a supervised learning problem, then scaled.\n",
    "Differencing was performed on the entire dataset prior to splitting into train and test sets for convenience. We could just as easily collect observations during the walk-forward validation and difference them as we go. I decided against it for readability.\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year_ID  name_common   age    mlb_ID  player_ID team_ID  stint_ID  \\\n",
      "90252 1978-01-01  Ozzie Smith  23.0  122439.0  smithoz01     SDP         1   \n",
      "90253 1979-01-01  Ozzie Smith  24.0  122439.0  smithoz01     SDP         1   \n",
      "90254 1980-01-01  Ozzie Smith  25.0  122439.0  smithoz01     SDP         1   \n",
      "90255 1981-01-01  Ozzie Smith  26.0  122439.0  smithoz01     SDP         1   \n",
      "90256 1982-01-01  Ozzie Smith  27.0  122439.0  smithoz01     STL         1   \n",
      "\n",
      "      lg_ID     PA    G  ...  oppRpG_rep  pyth_exponent  pyth_exponent_rep  \\\n",
      "90252    NL  668.0  159  ...     3.87019          1.812              1.801   \n",
      "90253    NL  649.0  156  ...     4.07843          1.828              1.827   \n",
      "90254    NL  712.0  158  ...     3.87045          1.812              1.801   \n",
      "90255    NL  507.0  110  ...     3.73275          1.787              1.783   \n",
      "90256    NL  567.0  140  ...     3.92351          1.819              1.808   \n",
      "\n",
      "       waa_win_perc  waa_win_perc_off  waa_win_perc_def  waa_win_perc_rep  \\\n",
      "90252        0.5072            0.5048            0.5096            0.4846   \n",
      "90253        0.4972            0.4872            0.5172            0.4853   \n",
      "90254        0.5183            0.5031            0.5228            0.4835   \n",
      "90255        0.4941            0.4900            0.5117            0.4830   \n",
      "90256        0.5217            0.5044            0.5245            0.4843   \n",
      "\n",
      "       OPS_plus   TOB_lg    TB_lg  \n",
      "90252   82.2811  203.264  218.064  \n",
      "90253   47.8761  203.712  226.934  \n",
      "90254   70.8553  221.169  229.532  \n",
      "90255   61.6917  158.891  164.745  \n",
      "90256   83.7029  185.734  189.198  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "players = read_csv('bsb_ref.csv', parse_dates=[4], squeeze=True, date_parser=parser)\n",
    "players = players.fillna(0)\n",
    "\n",
    "# focusing on players after 1975\n",
    "d1 = '1975-01-01'\n",
    "date = datetime.strptime(d1, '%Y-%m-%d')\n",
    "df_recent_players = players[players.year_ID >= date] #48k players\n",
    "\n",
    "#reorder columns so date is first\n",
    "df_recent_players = df_recent_players[['year_ID', 'name_common', 'age', 'mlb_ID', 'player_ID', 'team_ID', 'stint_ID',\n",
    "                                       'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "\n",
    "ozzie_Smith_DF = df_recent_players.loc[df_recent_players['name_common'] == 'Ozzie Smith']\n",
    "\n",
    "print(ozzie_Smith_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['team_ID' 'lg_ID' 'pitcher' 'player_ID' 'name_common'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-db86df20adee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mozzie_Smith_DF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'G'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mozzie_Smith_DF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'G'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mozzie_Smith_DF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stint_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mozzie_Smith_DF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stint_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mozzie_Smith_DF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mozzie_Smith_DF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"team_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lg_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pitcher\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"player_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"name_common\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mozzie_Smith_smallDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mozzie_Smith_DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m ozzie_Smith_smallDF = ozzie_Smith_smallDF.drop(['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m         )\n\u001b[1;32m   4104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3912\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3946\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5340\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['team_ID' 'lg_ID' 'pitcher' 'player_ID' 'name_common'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#data preprocessing to get LSTM working for player x\n",
    "#based on past yrs of player's performance, predict future performance  of player x)\n",
    "\n",
    "#cast all to same type float\n",
    "ozzie_Smith_DF['G'] = ozzie_Smith_DF['G'].astype(float)\n",
    "ozzie_Smith_DF['stint_ID'] = ozzie_Smith_DF['stint_ID'].astype(float)\n",
    "ozzie_Smith_DF = ozzie_Smith_DF.drop([\"team_ID\", \"lg_ID\", \"pitcher\", \"player_ID\", \"name_common\"], axis=1)\n",
    "ozzie_Smith_smallDF = ozzie_Smith_DF\n",
    "ozzie_Smith_smallDF = ozzie_Smith_smallDF.drop(['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg'], axis=1)\n",
    "\n",
    "print(ozzie_Smith_smallDF)\n",
    "# transform data to be stationary\n",
    "raw_values = ozzie_Smith_smallDF.values\n",
    "oneDim = np.stack(raw_values, axis =1)\n",
    "raw_values = oneDim[0]\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "print(\"supervised_values: \", len(supervised_values), supervised_values)\n",
    "train, test = supervised_values[0:-16], supervised_values[-16:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=1)\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "    # make one-step forecast\n",
    "    X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "    yhat = forecast_lstm(lstm_model, 1, X)\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    # invert differencing\n",
    "    yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "    expected = raw_values[len(train) + i + 1]\n",
    "    print('Year=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-16:], predictions))\n",
    "\n",
    "#print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-16:], label='WAR')\n",
    "pyplot.plot(predictions, label='Predicted War')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised_values:  18 [[ 0.   -1.61]\n",
      " [-1.61  3.43]\n",
      " [ 3.43 -4.08]\n",
      " [-4.08  4.04]\n",
      " [ 4.04 -1.25]\n",
      " [-1.25  1.2 ]\n",
      " [ 1.2   1.44]\n",
      " [ 1.44 -0.84]\n",
      " [-0.84  0.85]\n",
      " [ 0.85  0.17]\n",
      " [ 0.17  0.7 ]\n",
      " [ 0.7  -3.68]\n",
      " [-3.68  1.44]\n",
      " [ 1.44  0.04]\n",
      " [ 0.04 -1.99]\n",
      " [-1.99 -1.01]\n",
      " [-1.01 -2.83]\n",
      " [-2.83  2.28]]\n",
      "Year=1, Predicted=5.134601, Expected=0.990000\n",
      "Year=2, Predicted=4.671555, Expected=5.030000\n",
      "Year=3, Predicted=6.027902, Expected=3.780000\n",
      "Year=4, Predicted=5.771801, Expected=4.980000\n",
      "Year=5, Predicted=3.787515, Expected=6.420000\n",
      "Year=6, Predicted=2.489751, Expected=5.580000\n",
      "Year=7, Predicted=8.718642, Expected=6.430000\n",
      "Year=8, Predicted=6.074844, Expected=6.600000\n",
      "Year=9, Predicted=4.035533, Expected=7.300000\n",
      "Year=10, Predicted=3.404386, Expected=3.620000\n",
      "Year=11, Predicted=8.048232, Expected=5.060000\n",
      "Year=12, Predicted=6.071813, Expected=5.100000\n",
      "Year=13, Predicted=3.519431, Expected=3.110000\n",
      "Year=14, Predicted=6.800642, Expected=2.100000\n",
      "Year=15, Predicted=3.424824, Expected=-0.730000\n",
      "Year=16, Predicted=3.001495, Expected=1.550000\n",
      "Test RMSE: 2.588\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data preprocessing to get LSTM working for player x\n",
    "#based on past yrs of player's performance, predict future performance  of player x)\n",
    "\n",
    "#cast all to same type float\n",
    "# ozzie_Smith_DF['G'] = ozzie_Smith_DF['G'].astype(float)\n",
    "# ozzie_Smith_DF['stint_ID'] = ozzie_Smith_DF['stint_ID'].astype(float)\n",
    "# ozzie_Smith_DF = ozzie_Smith_DF.drop([\"team_ID\", \"lg_ID\", \"pitcher\", \"player_ID\", \"name_common\"], axis=1)\n",
    "# ozzie_Smith_smallDF = ozzie_Smith_DF\n",
    "# ozzie_Smith_smallDF = ozzie_Smith_smallDF.drop(['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "#                                        'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "#                                        'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "#                                        'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "#                                         'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "#                                        'WAA', 'WAA_off', 'WAA_def', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "#                                        'salary', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "#                                        'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "#                                        'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg'], axis=1)\n",
    "\n",
    "# print(ozzie_Smith_smallDF)\n",
    "# # transform data to be stationary\n",
    "raw_values = ozzie_Smith_smallDF.values\n",
    "oneDim = np.stack(raw_values, axis =1)\n",
    "raw_values = oneDim[0]\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "\n",
    "print(\"supervised_values: \", len(supervised_values), supervised_values)\n",
    "train, test = supervised_values[0:-16], supervised_values[-16:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=1)\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "    # make one-step forecast\n",
    "    X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "    yhat = forecast_lstm(lstm_model, 1, X)\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    # invert differencing\n",
    "    yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "    expected = raw_values[len(train) + i + 1]\n",
    "    print('Year=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-16:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-16:], label='OPS_plus')\n",
    "pyplot.plot(predictions, label='Predicted OPS_plus')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM not serialized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np \n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Include players from 1975 and onward. Change pitcher indicator from Y/N to 1/0 for comparison reasons. Make dictionary mapping mlb ID to player name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players with years 2013 - 2017\n",
    "# just go through list of players that are  not pitchers \n",
    "\n",
    "batting_data_path = 'bsb_ref.csv'\n",
    "# INFO:\n",
    "# 101,332 Players with up to 49 features each (exluding year, including team)\n",
    "# if metric not reported for player, set to mean by default\n",
    "\n",
    "df = pd.read_csv(batting_data_path)\n",
    "df = df.fillna(df.mean()) # replace NA with the mean of the df\n",
    "df_recent_players = df[df.year_ID >= 1975] #only players after 1975\n",
    "\n",
    "\n",
    "#reorder columns so date is first\n",
    "#shape is (54579, 49)\n",
    "#Note rows are players and for each player years' worth of metrics hence the 54,579\n",
    "df_recent_players = df_recent_players[['year_ID', 'name_common', 'age', 'mlb_ID', 'player_ID', 'team_ID', 'stint_ID',\n",
    "                                       'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "\n",
    "#change Y/N to 1/0 for pitcher indicator\n",
    "pd.Series(np.where(df_recent_players.pitcher.values == 'Y', 1, 0),\n",
    "          df_recent_players.index)  \n",
    "\n",
    "\n",
    "#Dictionary mapping player's mlb ID to their name\n",
    "playerNameToID = {}\n",
    "for index, row in df_recent_players.iterrows():\n",
    "    playerNameToID[row['mlb_ID']] = row['name_common']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe of hitters only with data for years 2013 - 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_pitchers = df_recent_players[df_recent_players['pitcher'] != 1] #only players that aren't pitchers\n",
    "players = list(set(df_not_pitchers['name_common'])) # just a set of all players\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013 = pd.DataFrame(columns=df_not_pitchers.columns)\n",
    "df_2014 = pd.DataFrame(columns=df_not_pitchers.columns)\n",
    "df_2015 = pd.DataFrame(columns=df_not_pitchers.columns)\n",
    "df_2016 = pd.DataFrame(columns=df_not_pitchers.columns)\n",
    "df_2017 = pd.DataFrame(columns=df_not_pitchers.columns)\n",
    "for player in players:\n",
    "    rows_per_player = df_not_pitchers[df_not_pitchers['name_common'] == player]\n",
    "    if 2013 in rows_per_player.values and 2014 in rows_per_player.values and 2015 in rows_per_player.values and 2016 in rows_per_player.values and 2017 in rows_per_player.values:\n",
    "        df_2013 = df_2013.append(rows_per_player[rows_per_player['year_ID'] == 2013].head(1))\n",
    "        df_2014 = df_2014.append(rows_per_player[rows_per_player['year_ID'] == 2014].head(1))\n",
    "        df_2015 = df_2015.append(rows_per_player[rows_per_player['year_ID'] == 2015].head(1))\n",
    "        df_2016 = df_2016.append(rows_per_player[rows_per_player['year_ID'] == 2016].head(1))\n",
    "        df_2017 = df_2017.append(rows_per_player[rows_per_player['year_ID'] == 2017].head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removed 'name_common', 'player_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2013:  (523, 49)\n",
      "df_2014:  (523, 49)\n",
      "df_2015:  (523, 49)\n",
      "df_2016:  (523, 49)\n",
      "df_2017:  (523, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_ID</th>\n",
       "      <th>age</th>\n",
       "      <th>mlb_ID</th>\n",
       "      <th>team_ID</th>\n",
       "      <th>stint_ID</th>\n",
       "      <th>lg_ID</th>\n",
       "      <th>PA</th>\n",
       "      <th>G</th>\n",
       "      <th>Inn</th>\n",
       "      <th>runs_bat</th>\n",
       "      <th>...</th>\n",
       "      <th>oppRpPA_rep</th>\n",
       "      <th>oppRpG_rep</th>\n",
       "      <th>pyth_exponent</th>\n",
       "      <th>pyth_exponent_rep</th>\n",
       "      <th>waa_win_perc</th>\n",
       "      <th>waa_win_perc_off</th>\n",
       "      <th>waa_win_perc_def</th>\n",
       "      <th>waa_win_perc_rep</th>\n",
       "      <th>TOB_lg</th>\n",
       "      <th>TB_lg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>89223</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.0</td>\n",
       "      <td>448609.0</td>\n",
       "      <td>ARI</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>37.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07154</td>\n",
       "      <td>4.02801</td>\n",
       "      <td>1.812</td>\n",
       "      <td>1.812</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100285</td>\n",
       "      <td>2013</td>\n",
       "      <td>31.0</td>\n",
       "      <td>425794.0</td>\n",
       "      <td>STL</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>32</td>\n",
       "      <td>241.7</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07154</td>\n",
       "      <td>3.94574</td>\n",
       "      <td>1.817</td>\n",
       "      <td>1.807</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.4907</td>\n",
       "      <td>23.335</td>\n",
       "      <td>28.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98471</td>\n",
       "      <td>2013</td>\n",
       "      <td>34.0</td>\n",
       "      <td>400284.0</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>531.0</td>\n",
       "      <td>131</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>16.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07154</td>\n",
       "      <td>3.89627</td>\n",
       "      <td>1.824</td>\n",
       "      <td>1.804</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.5194</td>\n",
       "      <td>0.4994</td>\n",
       "      <td>0.4850</td>\n",
       "      <td>171.407</td>\n",
       "      <td>190.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37295</td>\n",
       "      <td>2013</td>\n",
       "      <td>24.0</td>\n",
       "      <td>518748.0</td>\n",
       "      <td>CHC</td>\n",
       "      <td>2</td>\n",
       "      <td>NL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07154</td>\n",
       "      <td>4.02801</td>\n",
       "      <td>1.812</td>\n",
       "      <td>1.812</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57617</td>\n",
       "      <td>2013</td>\n",
       "      <td>29.0</td>\n",
       "      <td>476704.0</td>\n",
       "      <td>OAK</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>662.0</td>\n",
       "      <td>154</td>\n",
       "      <td>1339.3</td>\n",
       "      <td>11.78</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07418</td>\n",
       "      <td>4.13994</td>\n",
       "      <td>1.852</td>\n",
       "      <td>1.836</td>\n",
       "      <td>0.4972</td>\n",
       "      <td>0.5117</td>\n",
       "      <td>0.4897</td>\n",
       "      <td>0.4834</td>\n",
       "      <td>209.826</td>\n",
       "      <td>242.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84964</td>\n",
       "      <td>2016</td>\n",
       "      <td>31.0</td>\n",
       "      <td>502188.0</td>\n",
       "      <td>SFG</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>69.0</td>\n",
       "      <td>32</td>\n",
       "      <td>203.3</td>\n",
       "      <td>-9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08241</td>\n",
       "      <td>4.43002</td>\n",
       "      <td>1.871</td>\n",
       "      <td>1.866</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>21.762</td>\n",
       "      <td>26.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35823</td>\n",
       "      <td>2016</td>\n",
       "      <td>32.0</td>\n",
       "      <td>460086.0</td>\n",
       "      <td>KCR</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>506.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1100.3</td>\n",
       "      <td>-10.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07941</td>\n",
       "      <td>4.36142</td>\n",
       "      <td>1.865</td>\n",
       "      <td>1.862</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.4892</td>\n",
       "      <td>0.4994</td>\n",
       "      <td>0.4851</td>\n",
       "      <td>164.146</td>\n",
       "      <td>190.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50485</td>\n",
       "      <td>2016</td>\n",
       "      <td>32.0</td>\n",
       "      <td>435062.0</td>\n",
       "      <td>LAD</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>543.0</td>\n",
       "      <td>146</td>\n",
       "      <td>1090.3</td>\n",
       "      <td>-6.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08241</td>\n",
       "      <td>4.37923</td>\n",
       "      <td>1.868</td>\n",
       "      <td>1.863</td>\n",
       "      <td>0.4914</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.4941</td>\n",
       "      <td>0.4873</td>\n",
       "      <td>177.127</td>\n",
       "      <td>204.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67574</td>\n",
       "      <td>2016</td>\n",
       "      <td>28.0</td>\n",
       "      <td>489149.0</td>\n",
       "      <td>TBR</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>398.0</td>\n",
       "      <td>107</td>\n",
       "      <td>838.3</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07941</td>\n",
       "      <td>4.36979</td>\n",
       "      <td>1.868</td>\n",
       "      <td>1.863</td>\n",
       "      <td>0.4906</td>\n",
       "      <td>0.4945</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.4860</td>\n",
       "      <td>125.450</td>\n",
       "      <td>146.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78023</td>\n",
       "      <td>2016</td>\n",
       "      <td>25.0</td>\n",
       "      <td>624577.0</td>\n",
       "      <td>LAD</td>\n",
       "      <td>1</td>\n",
       "      <td>NL</td>\n",
       "      <td>368.0</td>\n",
       "      <td>104</td>\n",
       "      <td>744.3</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08241</td>\n",
       "      <td>4.38510</td>\n",
       "      <td>1.868</td>\n",
       "      <td>1.864</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.5037</td>\n",
       "      <td>0.4879</td>\n",
       "      <td>120.042</td>\n",
       "      <td>140.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2092 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year_ID   age    mlb_ID team_ID stint_ID lg_ID     PA    G     Inn  \\\n",
       "89223     2013  29.0  448609.0     ARI        1    NL    0.0   50    37.7   \n",
       "100285    2013  31.0  425794.0     STL        1    NL   81.0   32   241.7   \n",
       "98471     2013  34.0  400284.0     PHI        1    NL  531.0  131  1080.0   \n",
       "37295     2013  24.0  518748.0     CHC        2    NL    0.0   10     9.0   \n",
       "57617     2013  29.0  476704.0     OAK        1    AL  662.0  154  1339.3   \n",
       "...        ...   ...       ...     ...      ...   ...    ...  ...     ...   \n",
       "84964     2016  31.0  502188.0     SFG        1    NL   69.0   32   203.3   \n",
       "35823     2016  32.0  460086.0     KCR        1    AL  506.0  128  1100.3   \n",
       "50485     2016  32.0  435062.0     LAD        1    NL  543.0  146  1090.3   \n",
       "67574     2016  28.0  489149.0     TBR        1    AL  398.0  107   838.3   \n",
       "78023     2016  25.0  624577.0     LAD        1    NL  368.0  104   744.3   \n",
       "\n",
       "        runs_bat  ...  oppRpPA_rep  oppRpG_rep  pyth_exponent  \\\n",
       "89223       0.00  ...      0.07154     4.02801          1.812   \n",
       "100285     -7.62  ...      0.07154     3.94574          1.817   \n",
       "98471      16.96  ...      0.07154     3.89627          1.824   \n",
       "37295       0.00  ...      0.07154     4.02801          1.812   \n",
       "57617      11.78  ...      0.07418     4.13994          1.852   \n",
       "...          ...  ...          ...         ...            ...   \n",
       "84964      -9.00  ...      0.08241     4.43002          1.871   \n",
       "35823     -10.23  ...      0.07941     4.36142          1.865   \n",
       "50485      -6.08  ...      0.08241     4.37923          1.868   \n",
       "67574      -0.34  ...      0.07941     4.36979          1.868   \n",
       "78023      -1.56  ...      0.08241     4.38510          1.868   \n",
       "\n",
       "        pyth_exponent_rep  waa_win_perc  waa_win_perc_off  waa_win_perc_def  \\\n",
       "89223               1.812        0.5000            0.5000            0.5000   \n",
       "100285              1.807        0.5077            0.5077            0.5005   \n",
       "98471               1.804        0.5160            0.5194            0.4994   \n",
       "37295               1.812        0.5000            0.5000            0.5000   \n",
       "57617               1.836        0.4972            0.5117            0.4897   \n",
       "...                   ...           ...               ...               ...   \n",
       "84964               1.866        0.5002            0.5002            0.5004   \n",
       "35823               1.862        0.4924            0.4892            0.4994   \n",
       "50485               1.863        0.4914            0.4949            0.4941   \n",
       "67574               1.863        0.4906            0.4945            0.4901   \n",
       "78023               1.864        0.5019            0.4949            0.5037   \n",
       "\n",
       "        waa_win_perc_rep   TOB_lg    TB_lg  \n",
       "89223             0.5000    0.000    0.000  \n",
       "100285            0.4907   23.335   28.578  \n",
       "98471             0.4850  171.407  190.733  \n",
       "37295             0.5000    0.000    0.000  \n",
       "57617             0.4834  209.826  242.346  \n",
       "...                  ...      ...      ...  \n",
       "84964             0.4927   21.762   26.739  \n",
       "35823             0.4851  164.146  190.326  \n",
       "50485             0.4873  177.127  204.394  \n",
       "67574             0.4860  125.450  146.318  \n",
       "78023             0.4879  120.042  140.180  \n",
       "\n",
       "[2092 rows x 46 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removed 'name_common', 'player_ID', OPS_plus\n",
    "\n",
    "# df_2013 = df_2013[['year_ID', 'age', 'mlb_ID', 'team_ID', 'stint_ID',\n",
    "#                                        'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "#                                        'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "#                                        'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "#                                         'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "#                                        'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "#                                        'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "#                                        'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "#                                        'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "# df_2014 = df_2014[['year_ID', 'age', 'mlb_ID', 'team_ID', 'stint_ID',\n",
    "#                                        'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "#                                        'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "#                                        'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "#                                         'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "#                                        'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "#                                        'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "#                                        'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "#                                        'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "# df_2015 = df_2015[['year_ID', 'age', 'mlb_ID', 'team_ID', 'stint_ID',\n",
    "#                                        'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "#                                        'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "#                                        'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "#                                         'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "#                                        'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "#                                        'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "#                                        'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "#                                        'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "# df_2016 = df_2016[['year_ID', 'age', 'mlb_ID', 'team_ID', 'stint_ID',\n",
    "#                                        'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "#                                        'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "#                                        'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "#                                         'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "#                                        'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "#                                        'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "#                                        'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "#                                        'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "\n",
    "#frames = pd.concat([df_2013, df_2014, df_2015, df_2016], axis=0)\n",
    "\n",
    "print(\"df_2013: \", df_2013.shape)\n",
    "print(\"df_2014: \", df_2014.shape)\n",
    "print(\"df_2015: \", df_2015.shape)\n",
    "print(\"df_2016: \", df_2016.shape)\n",
    "print(\"df_2017: \", df_2017.shape)\n",
    "#print(\"frames: \", frames.shape)\n",
    "\n",
    "'''\n",
    "\n",
    "df_2013:  (523, 46)\n",
    "df_2014:  (523, 46)\n",
    "df_2015:  (523, 46)\n",
    "df_2016:  (523, 46)\n",
    "df_2017:  (523, 49)\n",
    "'''\n",
    "\n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2092, 49)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = pd.concat([df_2013, df_2014, df_2015, df_2016], axis=0)\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony Zych\n"
     ]
    }
   ],
   "source": [
    "print(playerNameToID[row['mlb_ID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_ID</th>\n",
       "      <th>name_common</th>\n",
       "      <th>age</th>\n",
       "      <th>mlb_ID</th>\n",
       "      <th>player_ID</th>\n",
       "      <th>team_ID</th>\n",
       "      <th>stint_ID</th>\n",
       "      <th>lg_ID</th>\n",
       "      <th>PA</th>\n",
       "      <th>G</th>\n",
       "      <th>...</th>\n",
       "      <th>oppRpG_rep</th>\n",
       "      <th>pyth_exponent</th>\n",
       "      <th>pyth_exponent_rep</th>\n",
       "      <th>waa_win_perc</th>\n",
       "      <th>waa_win_perc_off</th>\n",
       "      <th>waa_win_perc_def</th>\n",
       "      <th>waa_win_perc_rep</th>\n",
       "      <th>OPS_plus</th>\n",
       "      <th>TOB_lg</th>\n",
       "      <th>TB_lg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year_ID, name_common, age, mlb_ID, player_ID, team_ID, stint_ID, lg_ID, PA, G, Inn, runs_bat, runs_br, runs_dp, runs_field, runs_infield, runs_outfield, runs_catcher, runs_good_plays, runs_defense, runs_position, runs_position_p, runs_replacement, runs_above_rep, runs_above_avg, runs_above_avg_off, runs_above_avg_def, WAA, WAA_off, WAA_def, WAR, WAR_def, WAR_off, WAR_rep, salary, pitcher, teamRpG, oppRpG, oppRpPA_rep, oppRpG_rep, pyth_exponent, pyth_exponent_rep, waa_win_perc, waa_win_perc_off, waa_win_perc_def, waa_win_perc_rep, OPS_plus, TOB_lg, TB_lg]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 49 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_ID</th>\n",
       "      <th>age</th>\n",
       "      <th>mlb_ID</th>\n",
       "      <th>team_ID</th>\n",
       "      <th>stint_ID</th>\n",
       "      <th>lg_ID</th>\n",
       "      <th>PA</th>\n",
       "      <th>G</th>\n",
       "      <th>Inn</th>\n",
       "      <th>runs_bat</th>\n",
       "      <th>...</th>\n",
       "      <th>oppRpPA_rep</th>\n",
       "      <th>oppRpG_rep</th>\n",
       "      <th>pyth_exponent</th>\n",
       "      <th>pyth_exponent_rep</th>\n",
       "      <th>waa_win_perc</th>\n",
       "      <th>waa_win_perc_off</th>\n",
       "      <th>waa_win_perc_def</th>\n",
       "      <th>waa_win_perc_rep</th>\n",
       "      <th>TOB_lg</th>\n",
       "      <th>TB_lg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>2092</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>523.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.239484</td>\n",
       "      <td>488133.189771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.758126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480.890057</td>\n",
       "      <td>0.887902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075048</td>\n",
       "      <td>4.177498</td>\n",
       "      <td>1.840767</td>\n",
       "      <td>1.835868</td>\n",
       "      <td>0.499820</td>\n",
       "      <td>0.499568</td>\n",
       "      <td>0.500722</td>\n",
       "      <td>0.491045</td>\n",
       "      <td>69.050982</td>\n",
       "      <td>78.960871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.400215</td>\n",
       "      <td>61667.662888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.254719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>483.678516</td>\n",
       "      <td>10.508087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.194157</td>\n",
       "      <td>0.024275</td>\n",
       "      <td>0.023223</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>79.515351</td>\n",
       "      <td>90.656224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>112526.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-39.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070830</td>\n",
       "      <td>3.854270</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>1.799000</td>\n",
       "      <td>0.417600</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.482900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>452663.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.300000</td>\n",
       "      <td>-3.552500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071375</td>\n",
       "      <td>4.004552</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>1.816000</td>\n",
       "      <td>0.493275</td>\n",
       "      <td>0.494300</td>\n",
       "      <td>0.499402</td>\n",
       "      <td>0.485700</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>488768.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074640</td>\n",
       "      <td>4.160190</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>1.837000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>20.680000</td>\n",
       "      <td>24.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>520471.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>929.450000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076950</td>\n",
       "      <td>4.363282</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>1.862000</td>\n",
       "      <td>0.506200</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.501425</td>\n",
       "      <td>0.496100</td>\n",
       "      <td>140.719500</td>\n",
       "      <td>160.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>624577.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>726.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1453.700000</td>\n",
       "      <td>71.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082410</td>\n",
       "      <td>4.503060</td>\n",
       "      <td>2.058000</td>\n",
       "      <td>1.871000</td>\n",
       "      <td>0.793700</td>\n",
       "      <td>0.793700</td>\n",
       "      <td>0.541900</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>243.739000</td>\n",
       "      <td>283.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year_ID          age         mlb_ID team_ID  stint_ID lg_ID  \\\n",
       "count    2092.0  2092.000000    2092.000000    2092    2092.0  2092   \n",
       "unique      4.0          NaN            NaN      30       3.0     2   \n",
       "top      2016.0          NaN            NaN     BAL       1.0    AL   \n",
       "freq      523.0          NaN            NaN      94    1996.0  1090   \n",
       "mean        NaN    28.239484  488133.189771     NaN       NaN   NaN   \n",
       "std         NaN     3.400215   61667.662888     NaN       NaN   NaN   \n",
       "min         NaN    20.000000  112526.000000     NaN       NaN   NaN   \n",
       "25%         NaN    26.000000  452663.750000     NaN       NaN   NaN   \n",
       "50%         NaN    28.000000  488768.000000     NaN       NaN   NaN   \n",
       "75%         NaN    30.000000  520471.000000     NaN       NaN   NaN   \n",
       "max         NaN    43.000000  624577.000000     NaN       NaN   NaN   \n",
       "\n",
       "                 PA       G          Inn     runs_bat  ...  oppRpPA_rep  \\\n",
       "count   2092.000000  2092.0  2092.000000  2092.000000  ...  2092.000000   \n",
       "unique          NaN   163.0          NaN          NaN  ...          NaN   \n",
       "top             NaN     2.0          NaN          NaN  ...          NaN   \n",
       "freq            NaN   115.0          NaN          NaN  ...          NaN   \n",
       "mean     215.758126     NaN   480.890057     0.887902  ...     0.075048   \n",
       "std      247.254719     NaN   483.678516    10.508087  ...     0.003885   \n",
       "min        0.000000     NaN     0.000000   -39.010000  ...     0.070830   \n",
       "25%        1.000000     NaN    66.300000    -3.552500  ...     0.071375   \n",
       "50%       69.000000     NaN   205.150000     0.000000  ...     0.074640   \n",
       "75%      440.000000     NaN   929.450000     0.900000  ...     0.076950   \n",
       "max      726.000000     NaN  1453.700000    71.300000  ...     0.082410   \n",
       "\n",
       "         oppRpG_rep  pyth_exponent  pyth_exponent_rep  waa_win_perc  \\\n",
       "count   2092.000000    2092.000000        2092.000000   2092.000000   \n",
       "unique          NaN            NaN                NaN           NaN   \n",
       "top             NaN            NaN                NaN           NaN   \n",
       "freq            NaN            NaN                NaN           NaN   \n",
       "mean       4.177498       1.840767           1.835868      0.499820   \n",
       "std        0.194157       0.024275           0.023223      0.016949   \n",
       "min        3.854270       1.790000           1.799000      0.417600   \n",
       "25%        4.004552       1.820000           1.816000      0.493275   \n",
       "50%        4.160190       1.840000           1.837000      0.500000   \n",
       "75%        4.363282       1.865000           1.862000      0.506200   \n",
       "max        4.503060       2.058000           1.871000      0.793700   \n",
       "\n",
       "        waa_win_perc_off  waa_win_perc_def  waa_win_perc_rep       TOB_lg  \\\n",
       "count        2092.000000       2092.000000       2092.000000  2092.000000   \n",
       "unique               NaN               NaN               NaN          NaN   \n",
       "top                  NaN               NaN               NaN          NaN   \n",
       "freq                 NaN               NaN               NaN          NaN   \n",
       "mean            0.499568          0.500722          0.491045    69.050982   \n",
       "std             0.015717          0.006991          0.005839    79.515351   \n",
       "min             0.436000          0.463700          0.482900     0.000000   \n",
       "25%             0.494300          0.499402          0.485700     0.325000   \n",
       "50%             0.500000          0.500000          0.490500    20.680000   \n",
       "75%             0.505200          0.501425          0.496100   140.719500   \n",
       "max             0.793700          0.541900          0.500000   243.739000   \n",
       "\n",
       "              TB_lg  \n",
       "count   2092.000000  \n",
       "unique          NaN  \n",
       "top             NaN  \n",
       "freq            NaN  \n",
       "mean      78.960871  \n",
       "std       90.656224  \n",
       "min        0.000000  \n",
       "25%        0.414000  \n",
       "50%       24.667500  \n",
       "75%      160.669500  \n",
       "max      283.620000  \n",
       "\n",
       "[11 rows x 46 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (2092, 40)\n",
      "X val: \n",
      "[448609.0 1 0.0 50 37.7 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 -0.04 0.0 -0.04 0.0 0.0 4.02801 4.02801\n",
      " 0.07153999999999999 4.02801 1.8119999999999998 1.8119999999999998 0.5 0.5\n",
      " 0.5 0.5 0.0 0.0]\n",
      "X val: \n",
      "448609.0\n",
      "X val: \n"
     ]
    }
   ],
   "source": [
    "from numpy import zeros, newaxis\n",
    "allSamples = []\n",
    "y_list = []\n",
    "for index, row in frames.iterrows():\n",
    "    allSamples.append(row[['mlb_ID', 'stint_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', 'runs_infield', \n",
    "                           'runs_outfield', 'runs_catcher', 'runs_good_plays', 'runs_defense', 'runs_position', 'runs_position_p', \n",
    "                           'runs_replacement', 'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def', \n",
    "                           'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep', 'teamRpG', 'oppRpG', 'oppRpPA_rep', \n",
    "                           'oppRpG_rep', 'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off', 'waa_win_perc_def', \n",
    "                           'waa_win_perc_rep', 'TOB_lg', 'TB_lg']].values)\n",
    "    y_list.append(row[['OPS_plus']].values)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all.shape:  (2092, 40, 1)\n",
      "y_all.shape:  (2092, 1)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.reshape(allSamples, (-1, 40, 1))\n",
    "print(\"X_all.shape: \", X_all.shape)\n",
    "Y_all = np.array(y_list)\n",
    "print(\"y_all.shape: \", Y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (1569, 40, 1)\n",
      "Train:  (523, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "# separate test and train data\n",
    "# we could experiment here with removing features/PCA\n",
    "train = train_test_split(X_all, test_size=0.25, random_state=99)\n",
    "\n",
    "print(\"Train: \", train.shape)\n",
    "print(\"Train: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(523, 49)\n"
     ]
    }
   ],
   "source": [
    "print(df_2017.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST out different data split \n",
    "#80% train 10% val 10% test\n",
    "\n",
    "#data split: as informed by slides split for 30,000 examples \n",
    "#our example is a window and coming from a big expansive amount of data\n",
    "#5 second split based on papers using 5 sec split. We can play with this \n",
    "\n",
    "X_train, X_valtest, y_train, y_valtest = train_test_split(X_all, Y_all, test_size=0.2, random_state=99)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_new:  (1673, 40, 1)\n",
      "X_val_new:  (209, 40, 1)\n",
      "X_test_new:  (210, 40, 1)\n",
      "Y_train_new:  (1673, 1)\n",
      "Y_val_new:  (209, 1)\n",
      "Y_test_new:  (210, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[474699.0],\n",
       "        [1],\n",
       "        [0.0],\n",
       "        ...,\n",
       "        [0.5],\n",
       "        [0.0],\n",
       "        [0.0]],\n",
       "\n",
       "       [[462136.0],\n",
       "        [1],\n",
       "        [40.0],\n",
       "        ...,\n",
       "        [0.4958],\n",
       "        [11.335999999999999],\n",
       "        [12.825999999999999]],\n",
       "\n",
       "       [[467793.0],\n",
       "        [1],\n",
       "        [642.0],\n",
       "        ...,\n",
       "        [0.4837],\n",
       "        [201.845],\n",
       "        [214.452]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[452234.0],\n",
       "        [1],\n",
       "        [438.0],\n",
       "        ...,\n",
       "        [0.488],\n",
       "        [138.671],\n",
       "        [157.399]],\n",
       "\n",
       "       [[518875.0],\n",
       "        [1],\n",
       "        [0.0],\n",
       "        ...,\n",
       "        [0.5],\n",
       "        [0.0],\n",
       "        [0.0]],\n",
       "\n",
       "       [[572122.0],\n",
       "        [1],\n",
       "        [654.0],\n",
       "        ...,\n",
       "        [0.4835],\n",
       "        [202.43],\n",
       "        [225.734]]], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#train\n",
    "print(\"X_train_new: \",X_train.shape)\n",
    "\n",
    "#dev\n",
    "print(\"X_val_new: \",X_val.shape)\n",
    "\n",
    "#test\n",
    "print(\"X_test_new: \",X_test.shape)\n",
    "\n",
    "print(\"Y_train_new: \",y_train.shape)\n",
    "print(\"Y_val_new: \",y_val.shape)\n",
    "print(\"Y_test_new: \",y_test.shape)\n",
    "\n",
    "X_train\n",
    "#each samples should be [474699.0, 1, 0.0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_sequences is true bc we sliced data\n",
    "#http://faroit.com/keras-docs/1.0.1/getting-started/sequential-model-guide/\n",
    "#https://keras.io/getting-started/sequential-model-guide/\n",
    "lstmModel = Sequential()\n",
    "lstmModel.add(LSTM(64, return_sequences=True, input_shape=X_train.shape[1:]))\n",
    "lstmModel.add(LSTM(64))\n",
    "lstmModel.add(Dense(y_train.shape[1], activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 40, 64)            16896     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 49,985\n",
      "Trainable params: 49,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstmModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function: using cross entropy\n",
    "lstmModel.compile(Adam(),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1673 samples, validate on 209 samples\n",
      "Epoch 1/20\n",
      "1673/1673 [==============================] - 6s 4ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "1673/1673 [==============================] - 6s 4ms/step - loss: 8776.1168 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1673/1673 [==============================] - 6s 4ms/step - loss: 8776.1168 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1673/1673 [==============================] - 6s 3ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1673/1673 [==============================] - 6s 4ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1673/1673 [==============================] - 6s 4ms/step - loss: 8776.1170 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "1673/1673 [==============================] - 6s 4ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "1673/1673 [==============================] - 6s 4ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "1673/1673 [==============================] - 6s 3ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "1673/1673 [==============================] - 5s 3ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "1673/1673 [==============================] - 5s 3ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "1673/1673 [==============================] - 6s 3ms/step - loss: 8776.1170 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "1673/1673 [==============================] - 6s 3ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "1673/1673 [==============================] - 6s 3ms/step - loss: 8776.1168 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "1673/1673 [==============================] - 6s 3ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "1673/1673 [==============================] - 6s 3ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "1673/1673 [==============================] - 6s 4ms/step - loss: 8776.1168 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "1673/1673 [==============================] - 6s 4ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "1673/1673 [==============================] - 7s 4ms/step - loss: 8776.1168 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "1673/1673 [==============================] - 7s 4ms/step - loss: 8776.1169 - acc: 0.0000e+00 - val_loss: 7677.9756 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "lstm_history = lstmModel.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = lstmModel.predict(X_all, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function: using cross entropy\n",
    "lstmModel.compile(Adam(),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1673 samples, validate on 209 samples\n",
      "Epoch 1/5\n",
      "1673/1673 [==============================] - 8s 5ms/step - loss: 8776.1169 - mean_squared_error: 8776.1143 - val_loss: 7677.9756 - val_mean_squared_error: 7677.9761\n",
      "Epoch 2/5\n",
      "1504/1673 [=========================>....] - ETA: 0s - loss: 8939.2585 - mean_squared_error: 8939.2578"
     ]
    }
   ],
   "source": [
    "lstm_history = lstmModel.fit(X_train, y_train, epochs=5, validation_data=(X_val, y_val), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
