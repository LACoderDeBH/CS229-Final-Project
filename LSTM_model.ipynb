{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/StephanieBrito/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# load and plot dataset\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from pandas import concat\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Complete LSTM Example\n",
    "\n",
    "Load the dataset from CSV file.\n",
    "Transform the dataset to make it suitable for the LSTM model, including:\n",
    "Transforming the data to a supervised learning problem.\n",
    "Transforming the data to be stationary.\n",
    "Transforming the data so that it has the scale -1 to 1.\n",
    "Fitting a stateful LSTM network model to the training data.\n",
    "Evaluating the static LSTM model on the test data.\n",
    "Report the performance of the forecasts.\n",
    "Some things to note about the example:\n",
    "\n",
    "The scaling and inverse scaling behaviors have been moved to the functions scale() and invert_scale() for brevity.\n",
    "The test data is scaled using the fit of the scaler on the training data, as is required to ensure the min/max values of the test data do not influence the model.\n",
    "The order of data transforms was adjusted for convenience to first make the data stationary, then a supervised learning problem, then scaled.\n",
    "Differencing was performed on the entire dataset prior to splitting into train and test sets for convenience. We could just as easily collect observations during the walk-forward validation and difference them as we go. I decided against it for readability.\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          year_ID    name_common   age    mlb_ID  player_ID team_ID  stint_ID  \\\n",
      "0      2004-01-01  David Aardsma  22.0  430911.0  aardsda01     SFG         1   \n",
      "1      2006-01-01  David Aardsma  24.0  430911.0  aardsda01     CHC         1   \n",
      "2      2007-01-01  David Aardsma  25.0  430911.0  aardsda01     CHW         1   \n",
      "3      2008-01-01  David Aardsma  26.0  430911.0  aardsda01     BOS         1   \n",
      "4      2009-01-01  David Aardsma  27.0  430911.0  aardsda01     SEA         1   \n",
      "5      2010-01-01  David Aardsma  28.0  430911.0  aardsda01     SEA         1   \n",
      "6      2012-01-01  David Aardsma  30.0  430911.0  aardsda01     NYY         1   \n",
      "7      2013-01-01  David Aardsma  31.0  430911.0  aardsda01     NYM         1   \n",
      "8      2015-01-01  David Aardsma  33.0  430911.0  aardsda01     ATL         1   \n",
      "30     1975-01-01     Hank Aaron  41.0  110001.0  aaronha01     MIL         1   \n",
      "31     1976-01-01     Hank Aaron  42.0  110001.0  aaronha01     MIL         1   \n",
      "39     1977-01-01       Don Aase  22.0  110003.0   aasedo01     BOS         1   \n",
      "40     1978-01-01       Don Aase  23.0  110003.0   aasedo01     CAL         1   \n",
      "41     1979-01-01       Don Aase  24.0  110003.0   aasedo01     CAL         1   \n",
      "42     1980-01-01       Don Aase  25.0  110003.0   aasedo01     CAL         1   \n",
      "43     1981-01-01       Don Aase  26.0  110003.0   aasedo01     CAL         1   \n",
      "44     1982-01-01       Don Aase  27.0  110003.0   aasedo01     CAL         1   \n",
      "45     1984-01-01       Don Aase  29.0  110003.0   aasedo01     CAL         1   \n",
      "46     1985-01-01       Don Aase  30.0  110003.0   aasedo01     BAL         1   \n",
      "47     1986-01-01       Don Aase  31.0  110003.0   aasedo01     BAL         1   \n",
      "48     1987-01-01       Don Aase  32.0  110003.0   aasedo01     BAL         1   \n",
      "49     1988-01-01       Don Aase  33.0  110003.0   aasedo01     BAL         1   \n",
      "50     1989-01-01       Don Aase  34.0  110003.0   aasedo01     NYM         1   \n",
      "51     1990-01-01       Don Aase  35.0  110003.0   aasedo01     LAD         1   \n",
      "52     2001-01-01      Andy Abad  28.0  407577.0   abadan01     OAK         1   \n",
      "53     2003-01-01      Andy Abad  30.0  407577.0   abadan01     BOS         1   \n",
      "54     2006-01-01      Andy Abad  33.0  407577.0   abadan01     CIN         1   \n",
      "55     2010-01-01  Fernando Abad  24.0  472551.0   abadfe01     HOU         1   \n",
      "56     2011-01-01  Fernando Abad  25.0  472551.0   abadfe01     HOU         1   \n",
      "57     2012-01-01  Fernando Abad  26.0  472551.0   abadfe01     HOU         1   \n",
      "...           ...            ...   ...       ...        ...     ...       ...   \n",
      "107164 2001-01-01   Julio Zuleta  26.0  275936.0  zuletju01     CHC         1   \n",
      "107165 2006-01-01    Joel Zumaya  21.0  451491.0  zumayjo01     DET         1   \n",
      "107166 2007-01-01    Joel Zumaya  22.0  451491.0  zumayjo01     DET         1   \n",
      "107167 2008-01-01    Joel Zumaya  23.0  451491.0  zumayjo01     DET         1   \n",
      "107168 2009-01-01    Joel Zumaya  24.0  451491.0  zumayjo01     DET         1   \n",
      "107169 2010-01-01    Joel Zumaya  25.0  451491.0  zumayjo01     DET         1   \n",
      "107170 2013-01-01    Mike Zunino  22.0  572287.0  zuninmi01     SEA         1   \n",
      "107171 2014-01-01    Mike Zunino  23.0  572287.0  zuninmi01     SEA         1   \n",
      "107172 2015-01-01    Mike Zunino  24.0  572287.0  zuninmi01     SEA         1   \n",
      "107173 2016-01-01    Mike Zunino  25.0  572287.0  zuninmi01     SEA         1   \n",
      "107174 2017-01-01    Mike Zunino  26.0  572287.0  zuninmi01     SEA         1   \n",
      "107175 2018-01-01    Mike Zunino  27.0  572287.0  zuninmi01     SEA         1   \n",
      "107176 2019-01-01    Mike Zunino  28.0  572287.0  zuninmi01     TBR         1   \n",
      "107177 1991-01-01     Bob Zupcic  24.0  124787.0  zupcibo01     BOS         1   \n",
      "107178 1992-01-01     Bob Zupcic  25.0  124787.0  zupcibo01     BOS         1   \n",
      "107179 1993-01-01     Bob Zupcic  26.0  124787.0  zupcibo01     BOS         1   \n",
      "107180 1994-01-01     Bob Zupcic  27.0  124787.0  zupcibo01     BOS         1   \n",
      "107181 1994-01-01     Bob Zupcic  27.0  124787.0  zupcibo01     CHW         2   \n",
      "107185 1982-01-01   Paul Zuvella  23.0  124789.0  zuvelpa01     ATL         1   \n",
      "107186 1983-01-01   Paul Zuvella  24.0  124789.0  zuvelpa01     ATL         1   \n",
      "107187 1984-01-01   Paul Zuvella  25.0  124789.0  zuvelpa01     ATL         1   \n",
      "107188 1985-01-01   Paul Zuvella  26.0  124789.0  zuvelpa01     ATL         1   \n",
      "107189 1986-01-01   Paul Zuvella  27.0  124789.0  zuvelpa01     NYY         1   \n",
      "107190 1987-01-01   Paul Zuvella  28.0  124789.0  zuvelpa01     NYY         1   \n",
      "107191 1988-01-01   Paul Zuvella  29.0  124789.0  zuvelpa01     CLE         1   \n",
      "107192 1989-01-01   Paul Zuvella  30.0  124789.0  zuvelpa01     CLE         1   \n",
      "107193 1991-01-01   Paul Zuvella  32.0  124789.0  zuvelpa01     KCR         1   \n",
      "107208 2015-01-01      Tony Zych  24.0  543964.0   zychto01     SEA         1   \n",
      "107209 2016-01-01      Tony Zych  25.0  543964.0   zychto01     SEA         1   \n",
      "107210 2017-01-01      Tony Zych  26.0  543964.0   zychto01     SEA         1   \n",
      "\n",
      "       lg_ID     PA    G   ...     oppRpG_rep  pyth_exponent  \\\n",
      "0         NL    0.0   11   ...        4.67092          1.890   \n",
      "1         NL    3.0   43   ...        4.86457          1.912   \n",
      "2         AL    0.0    2   ...        4.85895          1.912   \n",
      "3         AL    1.0    5   ...        4.69650          1.893   \n",
      "4         AL    0.0    3   ...        4.79788          1.905   \n",
      "5         AL    0.0    4   ...        4.44684          1.864   \n",
      "6         AL    0.0    0   ...        0.00000          0.000   \n",
      "7         NL    0.0   41   ...        4.02801          1.812   \n",
      "8         NL    1.0   30   ...        4.22114          1.837   \n",
      "30        AL  543.0  137   ...        4.15661          1.839   \n",
      "31        AL  308.0   85   ...        3.84976          1.802   \n",
      "39        AL    0.0    0   ...        0.00000          0.000   \n",
      "40        AL    0.0    0   ...        0.00000          0.000   \n",
      "41        AL    0.0    0   ...        0.00000          0.000   \n",
      "42        AL    0.0    0   ...        0.00000          0.000   \n",
      "43        AL    0.0    0   ...        0.00000          0.000   \n",
      "44        AL    0.0    0   ...        0.00000          0.000   \n",
      "45        AL    0.0    0   ...        0.00000          0.000   \n",
      "46        AL    0.0    0   ...        0.00000          0.000   \n",
      "47        AL    0.0    0   ...        0.00000          0.000   \n",
      "48        AL    0.0    0   ...        0.00000          0.000   \n",
      "49        AL    0.0    0   ...        0.00000          0.000   \n",
      "50        NL    5.0   49   ...        3.91712          1.798   \n",
      "51        NL    0.0   32   ...        4.21496          1.836   \n",
      "52        AL    1.0    1   ...        4.84808          1.898   \n",
      "53        AL   19.0    9   ...        4.82470          1.893   \n",
      "54        NL    5.0    5   ...        4.83558          1.909   \n",
      "55        NL    1.0   22   ...        4.37978          1.856   \n",
      "56        NL    0.0   28   ...        4.15524          1.828   \n",
      "57        NL    7.0   36   ...        4.28341          1.844   \n",
      "...      ...    ...  ...   ...            ...            ...   \n",
      "107164    NL  118.0   49   ...        4.65853          1.891   \n",
      "107165    AL    0.0    5   ...        4.92028          1.919   \n",
      "107166    AL    0.0    0   ...        0.00000          0.000   \n",
      "107167    AL    0.0    2   ...        4.70400          1.894   \n",
      "107168    AL    0.0    3   ...        4.79788          1.905   \n",
      "107169    AL    0.0    4   ...        4.44684          1.864   \n",
      "107170    AL  193.0   52   ...        4.15945          1.846   \n",
      "107171    AL  476.0  131   ...        4.00246          1.823   \n",
      "107172    AL  386.0  112   ...        4.18052          1.837   \n",
      "107173    AL  192.0   55   ...        4.37798          1.878   \n",
      "107174    AL  435.0  124   ...        4.56970          1.901   \n",
      "107175    AL  405.0  113   ...        4.45023          1.878   \n",
      "107176    AL  289.0   90   ...        4.84100          1.912   \n",
      "107177    AL   27.0   18   ...        4.42161          1.857   \n",
      "107178    AL  432.0  124   ...        4.19272          1.846   \n",
      "107179    AL  326.0  141   ...        4.64608          1.891   \n",
      "107180    AL    4.0    4   ...        5.21230          1.930   \n",
      "107181    AL   97.0   32   ...        5.13613          1.940   \n",
      "107185    NL    1.0    2   ...        4.04482          1.809   \n",
      "107186    NL    8.0    3   ...        4.01355          1.813   \n",
      "107187    NL   27.0   11   ...        3.97830          1.808   \n",
      "107188    NL  210.0   81   ...        3.96497          1.814   \n",
      "107189    AL   57.0   21   ...        4.54481          1.862   \n",
      "107190    AL   36.0   14   ...        4.84613          1.899   \n",
      "107191    AL  146.0   51   ...        4.28123          1.850   \n",
      "107192    AL   60.0   24   ...        4.23326          1.850   \n",
      "107193    AL    0.0    2   ...        4.47535          1.868   \n",
      "107208    AL    0.0    0   ...        0.00000          0.000   \n",
      "107209    AL    0.0    0   ...        0.00000          0.000   \n",
      "107210    AL    0.0    4   ...        4.69540          1.893   \n",
      "\n",
      "        pyth_exponent_rep  waa_win_perc  waa_win_perc_off  waa_win_perc_def  \\\n",
      "0                   1.890        0.5000            0.5000            0.5000   \n",
      "1                   1.913        0.4990            0.4990            0.5000   \n",
      "2                   1.912        0.5000            0.5000            0.5000   \n",
      "3                   1.894        0.4970            0.4970            0.5000   \n",
      "4                   1.905        0.5000            0.5000            0.5000   \n",
      "5                   1.864        0.5000            0.5000            0.5000   \n",
      "6                   0.000        0.0000            0.0000            0.0000   \n",
      "7                   1.812        0.5000            0.5000            0.5000   \n",
      "8                   1.837        0.4996            0.4996            0.5000   \n",
      "30                  1.838        0.4861            0.4868            0.4899   \n",
      "31                  1.798        0.4917            0.4919            0.4906   \n",
      "39                  0.000        0.0000            0.0000            0.0000   \n",
      "40                  0.000        0.0000            0.0000            0.0000   \n",
      "41                  0.000        0.0000            0.0000            0.0000   \n",
      "42                  0.000        0.0000            0.0000            0.0000   \n",
      "43                  0.000        0.0000            0.0000            0.0000   \n",
      "44                  0.000        0.0000            0.0000            0.0000   \n",
      "45                  0.000        0.0000            0.0000            0.0000   \n",
      "46                  0.000        0.0000            0.0000            0.0000   \n",
      "47                  0.000        0.0000            0.0000            0.0000   \n",
      "48                  0.000        0.0000            0.0000            0.0000   \n",
      "49                  0.000        0.0000            0.0000            0.0000   \n",
      "50                  1.798        0.4985            0.4985            0.5000   \n",
      "51                  1.836        0.5000            0.5000            0.5000   \n",
      "52                  1.913        0.4700            0.4700            0.4990   \n",
      "53                  1.912        0.4570            0.4570            0.4964   \n",
      "54                  1.911        0.4929            0.4929            0.5002   \n",
      "55                  1.856        0.4993            0.4993            0.5000   \n",
      "56                  1.828        0.5000            0.5000            0.5000   \n",
      "57                  1.845        0.4987            0.4987            0.5000   \n",
      "...                   ...           ...               ...               ...   \n",
      "107164              1.893        0.4861            0.4888            0.4946   \n",
      "107165              1.919        0.5000            0.5000            0.5000   \n",
      "107166              0.000        0.0000            0.0000            0.0000   \n",
      "107167              1.894        0.5000            0.5000            0.5000   \n",
      "107168              1.905        0.5000            0.5000            0.5000   \n",
      "107169              1.864        0.5000            0.5000            0.5000   \n",
      "107170              1.837        0.4905            0.5008            0.4964   \n",
      "107171              1.817        0.4893            0.4960            0.5003   \n",
      "107172              1.839        0.4806            0.4816            0.5056   \n",
      "107173              1.863        0.5192            0.5116            0.5137   \n",
      "107174              1.886        0.5150            0.5141            0.5068   \n",
      "107175              1.872        0.5035            0.4962            0.5135   \n",
      "107176              1.916        0.4872            0.4818            0.5109   \n",
      "107177              1.864        0.4581            0.4814            0.4750   \n",
      "107178              1.841        0.4935            0.4936            0.4989   \n",
      "107179              1.893        0.4919            0.4887            0.5003   \n",
      "107180              1.953        0.3990            0.4559            0.4381   \n",
      "107181              1.948        0.4758            0.4747            0.4976   \n",
      "107185              1.816        0.4983            0.4870            0.5130   \n",
      "107186              1.816        0.4512            0.4835            0.4720   \n",
      "107187              1.811        0.4815            0.4846            0.5026   \n",
      "107188              1.810        0.4879            0.4971            0.4957   \n",
      "107189              1.881        0.4537            0.4566            0.5023   \n",
      "107190              1.915        0.4569            0.4631            0.4980   \n",
      "107191              1.850        0.4771            0.4890            0.4937   \n",
      "107192              1.844        0.4976            0.5012            0.4994   \n",
      "107193              1.868        0.4695            0.5000            0.4695   \n",
      "107208              0.000        0.0000            0.0000            0.0000   \n",
      "107209              0.000        0.0000            0.0000            0.0000   \n",
      "107210              1.893        0.5000            0.5000            0.5000   \n",
      "\n",
      "        waa_win_perc_rep  OPS_plus   TOB_lg    TB_lg  \n",
      "0                 0.5000    0.0000    0.000    0.000  \n",
      "1                 0.4998 -100.0000    0.694    0.896  \n",
      "2                 0.5000    0.0000    0.000    0.000  \n",
      "3                 0.4992 -100.0000    0.345    0.434  \n",
      "4                 0.5000    0.0000    0.000    0.000  \n",
      "5                 0.5000    0.0000    0.000    0.000  \n",
      "6                 0.0000    0.0000    0.000    0.000  \n",
      "7                 0.5000    0.0000    0.000    0.000  \n",
      "8                 0.4999 -100.0000    0.320    0.404  \n",
      "30                0.4846   94.9126  177.668  176.282  \n",
      "31                0.4851  102.2891   97.852   96.937  \n",
      "39                0.0000    0.0000    0.000    0.000  \n",
      "40                0.0000    0.0000    0.000    0.000  \n",
      "41                0.0000    0.0000    0.000    0.000  \n",
      "42                0.0000    0.0000    0.000    0.000  \n",
      "43                0.0000    0.0000    0.000    0.000  \n",
      "44                0.0000    0.0000    0.000    0.000  \n",
      "45                0.0000    0.0000    0.000    0.000  \n",
      "46                0.0000    0.0000    0.000    0.000  \n",
      "47                0.0000    0.0000    0.000    0.000  \n",
      "48                0.0000    0.0000    0.000    0.000  \n",
      "49                0.0000    0.0000    0.000    0.000  \n",
      "50                0.4996 -100.0000    1.574    1.848  \n",
      "51                0.5000    0.0000    0.000    0.000  \n",
      "52                0.4963 -100.0000    0.332    0.425  \n",
      "53                0.4922  -11.3089    6.470    7.444  \n",
      "54                0.4969   14.8106    1.742    1.349  \n",
      "55                0.4998 -100.0000    0.328    0.407  \n",
      "56                0.5000    0.0000    0.000    0.000  \n",
      "57                0.4993  -21.7251    2.286    2.896  \n",
      "...                  ...       ...      ...      ...  \n",
      "107164            0.4924   83.0639   39.282   45.591  \n",
      "107165            0.5000    0.0000    0.000    0.000  \n",
      "107166            0.0000    0.0000    0.000    0.000  \n",
      "107167            0.5000    0.0000    0.000    0.000  \n",
      "107168            0.5000    0.0000    0.000    0.000  \n",
      "107169            0.5000    0.0000    0.000    0.000  \n",
      "107170            0.4856   77.8174   59.888   67.608  \n",
      "107171            0.4855   87.6224  147.560  167.579  \n",
      "107172            0.4866   48.0738  117.860  141.400  \n",
      "107173            0.4869  113.1048   60.787   68.290  \n",
      "107174            0.4872  125.2748  138.287  162.617  \n",
      "107175            0.4867   84.5961  125.914  151.177  \n",
      "107176            0.4888   44.4700   92.278  115.497  \n",
      "107177            0.4944   26.7626    8.718   10.085  \n",
      "107178            0.4859   85.0120  142.842  154.879  \n",
      "107179            0.4913   75.3703  109.774  119.634  \n",
      "107180            0.4965 -100.0000    1.401    1.766  \n",
      "107181            0.4893   40.4689   31.815   37.858  \n",
      "107185            0.4981 -100.0000    0.334    0.393  \n",
      "107186            0.4898    9.6491    2.736    2.018  \n",
      "107187            0.4906   37.7035    9.107    9.862  \n",
      "107188            0.4900   69.9938   68.886   75.240  \n",
      "107189            0.4905  -22.6108   17.395   19.493  \n",
      "107190            0.4914   -5.2110   11.291   14.406  \n",
      "107191            0.4896   56.4277   45.126   51.233  \n",
      "107192            0.4903   99.1113   19.620   22.353  \n",
      "107193            0.5000    0.0000    0.000    0.000  \n",
      "107208            0.0000    0.0000    0.000    0.000  \n",
      "107209            0.0000    0.0000    0.000    0.000  \n",
      "107210            0.5000    0.0000    0.000    0.000  \n",
      "\n",
      "[54579 rows x 49 columns]\n",
      "     year_ID    name_common   age    mlb_ID  player_ID team_ID  stint_ID  \\\n",
      "4 2009-01-01  David Aardsma  27.0  430911.0  aardsda01     SEA         1   \n",
      "5 2010-01-01  David Aardsma  28.0  430911.0  aardsda01     SEA         1   \n",
      "6 2012-01-01  David Aardsma  30.0  430911.0  aardsda01     NYY         1   \n",
      "7 2013-01-01  David Aardsma  31.0  430911.0  aardsda01     NYM         1   \n",
      "8 2015-01-01  David Aardsma  33.0  430911.0  aardsda01     ATL         1   \n",
      "\n",
      "  lg_ID   PA   G  ...    oppRpG_rep  pyth_exponent  pyth_exponent_rep  \\\n",
      "4    AL  0.0   3  ...       4.79788          1.905              1.905   \n",
      "5    AL  0.0   4  ...       4.44684          1.864              1.864   \n",
      "6    AL  0.0   0  ...       0.00000          0.000              0.000   \n",
      "7    NL  0.0  41  ...       4.02801          1.812              1.812   \n",
      "8    NL  1.0  30  ...       4.22114          1.837              1.837   \n",
      "\n",
      "   waa_win_perc  waa_win_perc_off  waa_win_perc_def  waa_win_perc_rep  \\\n",
      "4        0.5000            0.5000               0.5            0.5000   \n",
      "5        0.5000            0.5000               0.5            0.5000   \n",
      "6        0.0000            0.0000               0.0            0.0000   \n",
      "7        0.5000            0.5000               0.5            0.5000   \n",
      "8        0.4996            0.4996               0.5            0.4999   \n",
      "\n",
      "   OPS_plus  TOB_lg  TB_lg  \n",
      "4       0.0    0.00  0.000  \n",
      "5       0.0    0.00  0.000  \n",
      "6       0.0    0.00  0.000  \n",
      "7       0.0    0.00  0.000  \n",
      "8    -100.0    0.32  0.404  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "players = read_csv('bsb_ref.csv', parse_dates=[4], squeeze=True, date_parser=parser)\n",
    "players = players.fillna(0)\n",
    "\n",
    "# focusing on players after 1975\n",
    "d1 = '1975-01-01'\n",
    "date = datetime.strptime(d1, '%Y-%m-%d')\n",
    "df_recent_players = players[players.year_ID >= date] #48k players\n",
    "\n",
    "#reorder columns so date is first\n",
    "df_recent_players = df_recent_players[['year_ID', 'name_common', 'age', 'mlb_ID', 'player_ID', 'team_ID', 'stint_ID',\n",
    "                                       'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "\n",
    "print(df_recent_players)\n",
    "df_recent_players = df_recent_players.loc[df_recent_players['name_common'] == 'David Aardsma']\n",
    "#df.loc[df['column_name'] == some_value]\n",
    "\n",
    "print(df_recent_players.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year_ID    name_common   age    mlb_ID  player_ID team_ID  stint_ID  \\\n",
      "0 2004-01-01  David Aardsma  22.0  430911.0  aardsda01     SFG         1   \n",
      "\n",
      "  lg_ID   PA   G  ...    oppRpG_rep  pyth_exponent  pyth_exponent_rep  \\\n",
      "0    NL  0.0  11  ...       4.67092           1.89               1.89   \n",
      "\n",
      "   waa_win_perc  waa_win_perc_off  waa_win_perc_def  waa_win_perc_rep  \\\n",
      "0           0.5               0.5               0.5               0.5   \n",
      "\n",
      "   OPS_plus  TOB_lg  TB_lg  \n",
      "0       0.0     0.0    0.0  \n",
      "\n",
      "[1 rows x 49 columns]\n",
      "year_ID               datetime64[ns]\n",
      "age                          float64\n",
      "mlb_ID                       float64\n",
      "stint_ID                     float64\n",
      "PA                           float64\n",
      "G                            float64\n",
      "Inn                          float64\n",
      "runs_bat                     float64\n",
      "runs_br                      float64\n",
      "runs_dp                      float64\n",
      "runs_field                   float64\n",
      "runs_infield                 float64\n",
      "runs_outfield                float64\n",
      "runs_catcher                 float64\n",
      "runs_good_plays              float64\n",
      "runs_defense                 float64\n",
      "runs_position                float64\n",
      "runs_position_p              float64\n",
      "runs_replacement             float64\n",
      "runs_above_rep               float64\n",
      "runs_above_avg               float64\n",
      "runs_above_avg_off           float64\n",
      "runs_above_avg_def           float64\n",
      "WAA                          float64\n",
      "WAA_off                      float64\n",
      "WAA_def                      float64\n",
      "WAR                          float64\n",
      "WAR_def                      float64\n",
      "WAR_off                      float64\n",
      "WAR_rep                      float64\n",
      "salary                       float64\n",
      "teamRpG                      float64\n",
      "oppRpG                       float64\n",
      "oppRpPA_rep                  float64\n",
      "oppRpG_rep                   float64\n",
      "pyth_exponent                float64\n",
      "pyth_exponent_rep            float64\n",
      "waa_win_perc                 float64\n",
      "waa_win_perc_off             float64\n",
      "waa_win_perc_def             float64\n",
      "waa_win_perc_rep             float64\n",
      "OPS_plus                     float64\n",
      "TOB_lg                       float64\n",
      "TB_lg                        float64\n",
      "dtype: object      year_ID   age    mlb_ID  stint_ID   PA     G   Inn  runs_bat  runs_br  \\\n",
      "0 2004-01-01  22.0  430911.0       1.0  0.0  11.0  10.7      0.00      0.0   \n",
      "1 2006-01-01  24.0  430911.0       1.0  3.0  43.0  53.0     -0.90      0.0   \n",
      "2 2007-01-01  25.0  430911.0       1.0  0.0   2.0  32.3      0.00      0.0   \n",
      "3 2008-01-01  26.0  430911.0       1.0  1.0   5.0  48.7     -0.29      0.0   \n",
      "4 2009-01-01  27.0  430911.0       1.0  0.0   3.0  71.3      0.00      0.0   \n",
      "5 2010-01-01  28.0  430911.0       1.0  0.0   4.0  49.7      0.00      0.0   \n",
      "6 2012-01-01  30.0  430911.0       1.0  0.0   0.0   1.0      0.00      0.0   \n",
      "7 2013-01-01  31.0  430911.0       1.0  0.0  41.0  39.7      0.00      0.0   \n",
      "8 2015-01-01  33.0  430911.0       1.0  1.0  30.0  30.7     -0.26      0.0   \n",
      "\n",
      "   runs_dp  ...    oppRpG_rep  pyth_exponent  pyth_exponent_rep  waa_win_perc  \\\n",
      "0      0.0  ...       4.67092          1.890              1.890        0.5000   \n",
      "1      0.0  ...       4.86457          1.912              1.913        0.4990   \n",
      "2      0.0  ...       4.85895          1.912              1.912        0.5000   \n",
      "3      0.0  ...       4.69650          1.893              1.894        0.4970   \n",
      "4      0.0  ...       4.79788          1.905              1.905        0.5000   \n",
      "5      0.0  ...       4.44684          1.864              1.864        0.5000   \n",
      "6      0.0  ...       0.00000          0.000              0.000        0.0000   \n",
      "7      0.0  ...       4.02801          1.812              1.812        0.5000   \n",
      "8      0.0  ...       4.22114          1.837              1.837        0.4996   \n",
      "\n",
      "   waa_win_perc_off  waa_win_perc_def  waa_win_perc_rep  OPS_plus  TOB_lg  \\\n",
      "0            0.5000               0.5            0.5000       0.0   0.000   \n",
      "1            0.4990               0.5            0.4998    -100.0   0.694   \n",
      "2            0.5000               0.5            0.5000       0.0   0.000   \n",
      "3            0.4970               0.5            0.4992    -100.0   0.345   \n",
      "4            0.5000               0.5            0.5000       0.0   0.000   \n",
      "5            0.5000               0.5            0.5000       0.0   0.000   \n",
      "6            0.0000               0.0            0.0000       0.0   0.000   \n",
      "7            0.5000               0.5            0.5000       0.0   0.000   \n",
      "8            0.4996               0.5            0.4999    -100.0   0.320   \n",
      "\n",
      "   TB_lg  \n",
      "0  0.000  \n",
      "1  0.896  \n",
      "2  0.000  \n",
      "3  0.434  \n",
      "4  0.000  \n",
      "5  0.000  \n",
      "6  0.000  \n",
      "7  0.000  \n",
      "8  0.404  \n",
      "\n",
      "[9 rows x 44 columns]\n",
      "    WAR\n",
      "0  0.00\n",
      "1 -0.04\n",
      "2  0.00\n",
      "3 -0.02\n",
      "4  0.00\n",
      "5  0.00\n",
      "6  0.00\n",
      "7  0.00\n",
      "8 -0.01\n",
      "supervised_values:  8 [[ 0.   -0.04]\n",
      " [-0.04  0.04]\n",
      " [ 0.04 -0.02]\n",
      " [-0.02  0.02]\n",
      " [ 0.02  0.  ]\n",
      " [ 0.    0.  ]\n",
      " [ 0.    0.  ]\n",
      " [ 0.   -0.01]]\n",
      "Year=1, Predicted=-0.013257, Expected=0.000000\n",
      "Year=2, Predicted=-0.014319, Expected=0.000000\n",
      "Year=3, Predicted=-0.016003, Expected=0.000000\n",
      "Year=4, Predicted=-0.017112, Expected=-0.010000\n",
      "Test RMSE: 0.013\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "#cast all to same type float\n",
    "\n",
    "davidAardsmaDf = df_recent_players.head(9)\n",
    "#print(davidAardsmaDf.head(0))\n",
    "print(davidAardsmaDf.head(1))\n",
    "\n",
    "\n",
    "davidAardsmaDf['G'] = davidAardsmaDf['G'].astype(float)\n",
    "davidAardsmaDf['stint_ID'] = davidAardsmaDf['stint_ID'].astype(float)\n",
    "davidAardsmaDf = davidAardsmaDf.drop([\"team_ID\", \"lg_ID\", \"pitcher\", \"player_ID\", \"name_common\"], axis=1)\n",
    "\n",
    "print(davidAardsmaDf.dtypes, davidAardsmaDf)\n",
    "\n",
    "smallDF = davidAardsmaDf\n",
    "smallDF = smallDF.drop(['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg'], axis=1)\n",
    "\n",
    "print(smallDF)\n",
    "# transform data to be stationary\n",
    "raw_values = smallDF.values\n",
    "oneDim = np.stack(raw_values, axis =1)\n",
    "raw_values = oneDim[0]\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "print(\"supervised_values: \", len(supervised_values), supervised_values)\n",
    "train, test = supervised_values[0:-4], supervised_values[-4:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=1)\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "    # make one-step forecast\n",
    "    X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "    yhat = forecast_lstm(lstm_model, 1, X)\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    # invert differencing\n",
    "    yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "    expected = raw_values[len(train) + i + 1]\n",
    "    print('Year=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-4:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-4:])\n",
    "pyplot.plot(predictions)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
