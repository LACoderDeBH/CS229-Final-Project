{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and plot dataset\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from pandas import concat\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Complete LSTM Example\n",
    "\n",
    "Load the dataset from CSV file.\n",
    "Transform the dataset to make it suitable for the LSTM model, including:\n",
    "Transforming the data to a supervised learning problem.\n",
    "Transforming the data to be stationary.\n",
    "Transforming the data so that it has the scale -1 to 1.\n",
    "Fitting a stateful LSTM network model to the training data.\n",
    "Evaluating the static LSTM model on the test data.\n",
    "Report the performance of the forecasts.\n",
    "Some things to note about the example:\n",
    "\n",
    "The scaling and inverse scaling behaviors have been moved to the functions scale() and invert_scale() for brevity.\n",
    "The test data is scaled using the fit of the scaler on the training data, as is required to ensure the min/max values of the test data do not influence the model.\n",
    "The order of data transforms was adjusted for convenience to first make the data stationary, then a supervised learning problem, then scaled.\n",
    "Differencing was performed on the entire dataset prior to splitting into train and test sets for convenience. We could just as easily collect observations during the walk-forward validation and difference them as we go. I decided against it for readability.\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year_ID    name_common   age    mlb_ID  player_ID team_ID  stint_ID  \\\n",
      "0 2004-01-01  David Aardsma  22.0  430911.0  aardsda01     SFG         1   \n",
      "1 2006-01-01  David Aardsma  24.0  430911.0  aardsda01     CHC         1   \n",
      "2 2007-01-01  David Aardsma  25.0  430911.0  aardsda01     CHW         1   \n",
      "3 2008-01-01  David Aardsma  26.0  430911.0  aardsda01     BOS         1   \n",
      "4 2009-01-01  David Aardsma  27.0  430911.0  aardsda01     SEA         1   \n",
      "\n",
      "  lg_ID   PA   G  ...  oppRpG_rep  pyth_exponent  pyth_exponent_rep  \\\n",
      "0    NL  0.0  11  ...     4.67092          1.890              1.890   \n",
      "1    NL  3.0  43  ...     4.86457          1.912              1.913   \n",
      "2    AL  0.0   2  ...     4.85895          1.912              1.912   \n",
      "3    AL  1.0   5  ...     4.69650          1.893              1.894   \n",
      "4    AL  0.0   3  ...     4.79788          1.905              1.905   \n",
      "\n",
      "   waa_win_perc  waa_win_perc_off  waa_win_perc_def  waa_win_perc_rep  \\\n",
      "0         0.500             0.500               0.5            0.5000   \n",
      "1         0.499             0.499               0.5            0.4998   \n",
      "2         0.500             0.500               0.5            0.5000   \n",
      "3         0.497             0.497               0.5            0.4992   \n",
      "4         0.500             0.500               0.5            0.5000   \n",
      "\n",
      "   OPS_plus  TOB_lg  TB_lg  \n",
      "0       0.0   0.000  0.000  \n",
      "1    -100.0   0.694  0.896  \n",
      "2       0.0   0.000  0.000  \n",
      "3    -100.0   0.345  0.434  \n",
      "4       0.0   0.000  0.000  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "players = read_csv('bsb_ref.csv', parse_dates=[4], squeeze=True, date_parser=parser)\n",
    "players = players.fillna(0)\n",
    "\n",
    "# focusing on players after 1975\n",
    "d1 = '1975-01-01'\n",
    "date = datetime.strptime(d1, '%Y-%m-%d')\n",
    "df_recent_players = players[players.year_ID >= date] #48k players\n",
    "\n",
    "#reorder columns so date is first\n",
    "df_recent_players = df_recent_players[['year_ID', 'name_common', 'age', 'mlb_ID', 'player_ID', 'team_ID', 'stint_ID',\n",
    "                                       'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "\n",
    "df_recent_players = df_recent_players.loc[df_recent_players['name_common'] == 'David Aardsma']\n",
    "#df.loc[df['column_name'] == some_value]\n",
    "\n",
    "print(df_recent_players.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year_ID    name_common   age    mlb_ID  player_ID team_ID  stint_ID  \\\n",
      "0 2004-01-01  David Aardsma  22.0  430911.0  aardsda01     SFG         1   \n",
      "\n",
      "  lg_ID   PA   G  ...  oppRpG_rep  pyth_exponent  pyth_exponent_rep  \\\n",
      "0    NL  0.0  11  ...     4.67092           1.89               1.89   \n",
      "\n",
      "   waa_win_perc  waa_win_perc_off  waa_win_perc_def  waa_win_perc_rep  \\\n",
      "0           0.5               0.5               0.5               0.5   \n",
      "\n",
      "   OPS_plus  TOB_lg  TB_lg  \n",
      "0       0.0     0.0    0.0  \n",
      "\n",
      "[1 rows x 49 columns]\n",
      "year_ID               datetime64[ns]\n",
      "age                          float64\n",
      "mlb_ID                       float64\n",
      "stint_ID                     float64\n",
      "PA                           float64\n",
      "G                            float64\n",
      "Inn                          float64\n",
      "runs_bat                     float64\n",
      "runs_br                      float64\n",
      "runs_dp                      float64\n",
      "runs_field                   float64\n",
      "runs_infield                 float64\n",
      "runs_outfield                float64\n",
      "runs_catcher                 float64\n",
      "runs_good_plays              float64\n",
      "runs_defense                 float64\n",
      "runs_position                float64\n",
      "runs_position_p              float64\n",
      "runs_replacement             float64\n",
      "runs_above_rep               float64\n",
      "runs_above_avg               float64\n",
      "runs_above_avg_off           float64\n",
      "runs_above_avg_def           float64\n",
      "WAA                          float64\n",
      "WAA_off                      float64\n",
      "WAA_def                      float64\n",
      "WAR                          float64\n",
      "WAR_def                      float64\n",
      "WAR_off                      float64\n",
      "WAR_rep                      float64\n",
      "salary                       float64\n",
      "teamRpG                      float64\n",
      "oppRpG                       float64\n",
      "oppRpPA_rep                  float64\n",
      "oppRpG_rep                   float64\n",
      "pyth_exponent                float64\n",
      "pyth_exponent_rep            float64\n",
      "waa_win_perc                 float64\n",
      "waa_win_perc_off             float64\n",
      "waa_win_perc_def             float64\n",
      "waa_win_perc_rep             float64\n",
      "OPS_plus                     float64\n",
      "TOB_lg                       float64\n",
      "TB_lg                        float64\n",
      "dtype: object      year_ID   age    mlb_ID  stint_ID   PA     G   Inn  runs_bat  runs_br  \\\n",
      "0 2004-01-01  22.0  430911.0       1.0  0.0  11.0  10.7      0.00      0.0   \n",
      "1 2006-01-01  24.0  430911.0       1.0  3.0  43.0  53.0     -0.90      0.0   \n",
      "2 2007-01-01  25.0  430911.0       1.0  0.0   2.0  32.3      0.00      0.0   \n",
      "3 2008-01-01  26.0  430911.0       1.0  1.0   5.0  48.7     -0.29      0.0   \n",
      "4 2009-01-01  27.0  430911.0       1.0  0.0   3.0  71.3      0.00      0.0   \n",
      "5 2010-01-01  28.0  430911.0       1.0  0.0   4.0  49.7      0.00      0.0   \n",
      "6 2012-01-01  30.0  430911.0       1.0  0.0   0.0   1.0      0.00      0.0   \n",
      "7 2013-01-01  31.0  430911.0       1.0  0.0  41.0  39.7      0.00      0.0   \n",
      "8 2015-01-01  33.0  430911.0       1.0  1.0  30.0  30.7     -0.26      0.0   \n",
      "\n",
      "   runs_dp  ...  oppRpG_rep  pyth_exponent  pyth_exponent_rep  waa_win_perc  \\\n",
      "0      0.0  ...     4.67092          1.890              1.890        0.5000   \n",
      "1      0.0  ...     4.86457          1.912              1.913        0.4990   \n",
      "2      0.0  ...     4.85895          1.912              1.912        0.5000   \n",
      "3      0.0  ...     4.69650          1.893              1.894        0.4970   \n",
      "4      0.0  ...     4.79788          1.905              1.905        0.5000   \n",
      "5      0.0  ...     4.44684          1.864              1.864        0.5000   \n",
      "6      0.0  ...     0.00000          0.000              0.000        0.0000   \n",
      "7      0.0  ...     4.02801          1.812              1.812        0.5000   \n",
      "8      0.0  ...     4.22114          1.837              1.837        0.4996   \n",
      "\n",
      "   waa_win_perc_off  waa_win_perc_def  waa_win_perc_rep  OPS_plus  TOB_lg  \\\n",
      "0            0.5000               0.5            0.5000       0.0   0.000   \n",
      "1            0.4990               0.5            0.4998    -100.0   0.694   \n",
      "2            0.5000               0.5            0.5000       0.0   0.000   \n",
      "3            0.4970               0.5            0.4992    -100.0   0.345   \n",
      "4            0.5000               0.5            0.5000       0.0   0.000   \n",
      "5            0.5000               0.5            0.5000       0.0   0.000   \n",
      "6            0.0000               0.0            0.0000       0.0   0.000   \n",
      "7            0.5000               0.5            0.5000       0.0   0.000   \n",
      "8            0.4996               0.5            0.4999    -100.0   0.320   \n",
      "\n",
      "   TB_lg  \n",
      "0  0.000  \n",
      "1  0.896  \n",
      "2  0.000  \n",
      "3  0.434  \n",
      "4  0.000  \n",
      "5  0.000  \n",
      "6  0.000  \n",
      "7  0.000  \n",
      "8  0.404  \n",
      "\n",
      "[9 rows x 44 columns]\n",
      "    WAR\n",
      "0  0.00\n",
      "1 -0.04\n",
      "2  0.00\n",
      "3 -0.02\n",
      "4  0.00\n",
      "5  0.00\n",
      "6  0.00\n",
      "7  0.00\n",
      "8 -0.01\n",
      "supervised_values:  8 [[ 0.   -0.04]\n",
      " [-0.04  0.04]\n",
      " [ 0.04 -0.02]\n",
      " [-0.02  0.02]\n",
      " [ 0.02  0.  ]\n",
      " [ 0.    0.  ]\n",
      " [ 0.    0.  ]\n",
      " [ 0.   -0.01]]\n",
      "Year=1, Predicted=-0.044293, Expected=0.000000\n",
      "Year=2, Predicted=-0.009411, Expected=0.000000\n",
      "Year=3, Predicted=-0.033573, Expected=0.000000\n",
      "Year=4, Predicted=-0.033402, Expected=-0.010000\n",
      "Test RMSE: 0.031\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "#cast all to same type float\n",
    "\n",
    "davidAardsmaDf = df_recent_players.head(9)\n",
    "#print(davidAardsmaDf.head(0))\n",
    "print(davidAardsmaDf.head(1))\n",
    "\n",
    "\n",
    "davidAardsmaDf['G'] = davidAardsmaDf['G'].astype(float)\n",
    "davidAardsmaDf['stint_ID'] = davidAardsmaDf['stint_ID'].astype(float)\n",
    "davidAardsmaDf = davidAardsmaDf.drop([\"team_ID\", \"lg_ID\", \"pitcher\", \"player_ID\", \"name_common\"], axis=1)\n",
    "\n",
    "print(davidAardsmaDf.dtypes, davidAardsmaDf)\n",
    "\n",
    "smallDF = davidAardsmaDf\n",
    "smallDF = smallDF.drop(['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg'], axis=1)\n",
    "\n",
    "print(smallDF)\n",
    "# transform data to be stationary\n",
    "raw_values = smallDF.values\n",
    "oneDim = np.stack(raw_values, axis =1)\n",
    "raw_values = oneDim[0]\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "print(\"supervised_values: \", len(supervised_values), supervised_values)\n",
    "train, test = supervised_values[0:-4], supervised_values[-4:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=1)\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "    # make one-step forecast\n",
    "    X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "    yhat = forecast_lstm(lstm_model, 1, X)\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    # invert differencing\n",
    "    yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "    expected = raw_values[len(train) + i + 1]\n",
    "    print('Year=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-4:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-4:])\n",
    "pyplot.plot(predictions)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
