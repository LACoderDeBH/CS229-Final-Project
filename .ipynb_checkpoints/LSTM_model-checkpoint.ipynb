{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and plot dataset\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from pandas import concat\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Complete LSTM Example\n",
    "\n",
    "Load the dataset from CSV file.\n",
    "Transform the dataset to make it suitable for the LSTM model, including:\n",
    "Transforming the data to a supervised learning problem.\n",
    "Transforming the data to be stationary.\n",
    "Transforming the data so that it has the scale -1 to 1.\n",
    "Fitting a stateful LSTM network model to the training data.\n",
    "Evaluating the static LSTM model on the test data.\n",
    "Report the performance of the forecasts.\n",
    "Some things to note about the example:\n",
    "\n",
    "The scaling and inverse scaling behaviors have been moved to the functions scale() and invert_scale() for brevity.\n",
    "The test data is scaled using the fit of the scaler on the training data, as is required to ensure the min/max values of the test data do not influence the model.\n",
    "The order of data transforms was adjusted for convenience to first make the data stationary, then a supervised learning problem, then scaled.\n",
    "Differencing was performed on the entire dataset prior to splitting into train and test sets for convenience. We could just as easily collect observations during the walk-forward validation and difference them as we go. I decided against it for readability.\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year_ID  name_common   age    mlb_ID  player_ID team_ID  stint_ID  \\\n",
      "90252 1978-01-01  Ozzie Smith  23.0  122439.0  smithoz01     SDP         1   \n",
      "90253 1979-01-01  Ozzie Smith  24.0  122439.0  smithoz01     SDP         1   \n",
      "90254 1980-01-01  Ozzie Smith  25.0  122439.0  smithoz01     SDP         1   \n",
      "90255 1981-01-01  Ozzie Smith  26.0  122439.0  smithoz01     SDP         1   \n",
      "90256 1982-01-01  Ozzie Smith  27.0  122439.0  smithoz01     STL         1   \n",
      "\n",
      "      lg_ID     PA    G  ...  oppRpG_rep  pyth_exponent  pyth_exponent_rep  \\\n",
      "90252    NL  668.0  159  ...     3.87019          1.812              1.801   \n",
      "90253    NL  649.0  156  ...     4.07843          1.828              1.827   \n",
      "90254    NL  712.0  158  ...     3.87045          1.812              1.801   \n",
      "90255    NL  507.0  110  ...     3.73275          1.787              1.783   \n",
      "90256    NL  567.0  140  ...     3.92351          1.819              1.808   \n",
      "\n",
      "       waa_win_perc  waa_win_perc_off  waa_win_perc_def  waa_win_perc_rep  \\\n",
      "90252        0.5072            0.5048            0.5096            0.4846   \n",
      "90253        0.4972            0.4872            0.5172            0.4853   \n",
      "90254        0.5183            0.5031            0.5228            0.4835   \n",
      "90255        0.4941            0.4900            0.5117            0.4830   \n",
      "90256        0.5217            0.5044            0.5245            0.4843   \n",
      "\n",
      "       OPS_plus   TOB_lg    TB_lg  \n",
      "90252   82.2811  203.264  218.064  \n",
      "90253   47.8761  203.712  226.934  \n",
      "90254   70.8553  221.169  229.532  \n",
      "90255   61.6917  158.891  164.745  \n",
      "90256   83.7029  185.734  189.198  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "players = read_csv('bsb_ref.csv', parse_dates=[4], squeeze=True, date_parser=parser)\n",
    "players = players.fillna(0)\n",
    "\n",
    "# focusing on players after 1975\n",
    "d1 = '1975-01-01'\n",
    "date = datetime.strptime(d1, '%Y-%m-%d')\n",
    "df_recent_players = players[players.year_ID >= date] #48k players\n",
    "\n",
    "#reorder columns so date is first\n",
    "df_recent_players = df_recent_players[['year_ID', 'name_common', 'age', 'mlb_ID', 'player_ID', 'team_ID', 'stint_ID',\n",
    "                                       'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "\n",
    "ozzie_Smith_DF = df_recent_players.loc[df_recent_players['name_common'] == 'Ozzie Smith']\n",
    "\n",
    "print(ozzie_Smith_DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year_ID   age    mlb_ID  stint_ID     PA      G     Inn  runs_bat  \\\n",
      "90252 1978-01-01  23.0  122439.0       1.0  668.0  159.0  1327.0     -8.73   \n",
      "90253 1979-01-01  24.0  122439.0       1.0  649.0  156.0  1339.0    -34.65   \n",
      "90254 1980-01-01  25.0  122439.0       1.0  712.0  158.0  1398.3    -16.15   \n",
      "90255 1981-01-01  26.0  122439.0       1.0  507.0  110.0   986.3    -18.33   \n",
      "90256 1982-01-01  27.0  122439.0       1.0  567.0  140.0  1249.0    -10.58   \n",
      "90257 1983-01-01  28.0  122439.0       1.0  626.0  159.0  1343.7    -11.51   \n",
      "90258 1984-01-01  29.0  122439.0       1.0  484.0  124.0  1065.3      1.64   \n",
      "90259 1985-01-01  30.0  122439.0       1.0  615.0  158.0  1407.0      2.48   \n",
      "90260 1986-01-01  31.0  122439.0       1.0  609.0  153.0  1287.0     -1.26   \n",
      "90261 1987-01-01  32.0  122439.0       1.0  706.0  158.0  1357.3     10.43   \n",
      "90262 1988-01-01  33.0  122439.0       1.0  669.0  153.0  1329.0      0.68   \n",
      "90263 1989-01-01  34.0  122439.0       1.0  664.0  155.0  1336.3     -1.96   \n",
      "90264 1990-01-01  35.0  122439.0       1.0  592.0  143.0  1203.3    -13.81   \n",
      "90265 1991-01-01  36.0  122439.0       1.0  641.0  150.0  1253.3     10.16   \n",
      "90266 1992-01-01  37.0  122439.0       1.0  590.0  132.0  1156.3      3.55   \n",
      "90267 1993-01-01  38.0  122439.0       1.0  603.0  141.0  1139.3     -4.81   \n",
      "90268 1994-01-01  39.0  122439.0       1.0  433.0   98.0   822.0    -12.10   \n",
      "90269 1995-01-01  40.0  122439.0       1.0  182.0   44.0   343.3    -14.02   \n",
      "90270 1996-01-01  41.0  122439.0       1.0  261.0   82.0   442.7      2.19   \n",
      "\n",
      "       runs_br  runs_dp  ...  oppRpG_rep  pyth_exponent  pyth_exponent_rep  \\\n",
      "90252     4.10     1.23  ...     3.87019          1.812              1.801   \n",
      "90253     5.05     1.13  ...     4.07843          1.828              1.827   \n",
      "90254     7.82     1.91  ...     3.87045          1.812              1.801   \n",
      "90255     1.18     0.42  ...     3.73275          1.787              1.783   \n",
      "90256     4.36     2.64  ...     3.92351          1.819              1.808   \n",
      "90257     4.62     1.27  ...     3.97014          1.824              1.814   \n",
      "90258     3.33     2.72  ...     3.92880          1.825              1.808   \n",
      "90259     3.73     1.28  ...     3.92056          1.823              1.807   \n",
      "90260     6.32     1.57  ...     4.01681          1.835              1.820   \n",
      "90261     5.60     0.79  ...     4.37780          1.883              1.865   \n",
      "90262     9.88     0.25  ...     3.71552          1.799              1.781   \n",
      "90263     5.34     1.04  ...     3.78439          1.804              1.789   \n",
      "90264     4.79     1.98  ...     4.08178          1.837              1.828   \n",
      "90265     4.93     1.10  ...     3.96587          1.832              1.813   \n",
      "90266     3.94     1.51  ...     3.73529          1.799              1.782   \n",
      "90267     3.48     1.54  ...     4.37116          1.874              1.863   \n",
      "90268     1.31     1.56  ...     4.50315          1.884              1.879   \n",
      "90269     0.29    -0.65  ...     4.50546          1.870              1.879   \n",
      "90270    -0.76     0.19  ...     4.59673          1.897              1.888   \n",
      "\n",
      "       waa_win_perc  waa_win_perc_off  waa_win_perc_def  waa_win_perc_rep  \\\n",
      "90252        0.5072            0.5048            0.5096            0.4846   \n",
      "90253        0.4972            0.4872            0.5172            0.4853   \n",
      "90254        0.5183            0.5031            0.5228            0.4835   \n",
      "90255        0.4941            0.4900            0.5117            0.4830   \n",
      "90256        0.5217            0.5044            0.5245            0.4843   \n",
      "90257        0.5112            0.5030            0.5151            0.4849   \n",
      "90258        0.5267            0.5139            0.5199            0.4849   \n",
      "90259        0.5271            0.5125            0.5219            0.4849   \n",
      "90260        0.5232            0.5115            0.5185            0.4849   \n",
      "90261        0.5263            0.5174            0.5155            0.4847   \n",
      "90262        0.5291            0.5154            0.5210            0.4831   \n",
      "90263        0.5346            0.5105            0.5314            0.4842   \n",
      "90264        0.5119            0.5014            0.5173            0.4853   \n",
      "90265        0.5210            0.5186            0.5092            0.4848   \n",
      "90266        0.5263            0.5152            0.5186            0.4851   \n",
      "90267        0.5090            0.5062            0.5089            0.4862   \n",
      "90268        0.5089            0.4966            0.5185            0.4864   \n",
      "90269        0.4717            0.4719            0.5055            0.4869   \n",
      "90270        0.5110            0.5060            0.5090            0.4900   \n",
      "\n",
      "       OPS_plus   TOB_lg    TB_lg  \n",
      "90252   82.2811  203.264  218.064  \n",
      "90253   47.8761  203.712  226.934  \n",
      "90254   70.8553  221.169  229.532  \n",
      "90255   61.6917  158.891  164.745  \n",
      "90256   83.7029  185.734  189.198  \n",
      "90257   82.0821  206.127  216.274  \n",
      "90258   95.3648  154.009  156.395  \n",
      "90259  101.4293  198.707  208.088  \n",
      "90260   97.9170  198.237  202.567  \n",
      "90261  105.4788  236.862  253.740  \n",
      "90262   97.7764  211.094  217.293  \n",
      "90263   97.3352  212.290  227.238  \n",
      "90264   76.5401  193.401  203.264  \n",
      "90265  111.7935  206.566  212.355  \n",
      "90266  105.2098  185.307  194.923  \n",
      "90267   88.9244  197.932  222.033  \n",
      "90268   78.3334  143.312  162.116  \n",
      "90269   42.0689   59.720   65.130  \n",
      "90270   94.1023   85.801   95.408  \n",
      "\n",
      "[19 rows x 44 columns]\n",
      "supervised_values:  18 [[                0 31536000000000000]\n",
      " [31536000000000000 31536000000000000]\n",
      " [31536000000000000 31622400000000000]\n",
      " [31622400000000000 31536000000000000]\n",
      " [31536000000000000 31536000000000000]\n",
      " [31536000000000000 31536000000000000]\n",
      " [31536000000000000 31622400000000000]\n",
      " [31622400000000000 31536000000000000]\n",
      " [31536000000000000 31536000000000000]\n",
      " [31536000000000000 31536000000000000]\n",
      " [31536000000000000 31622400000000000]\n",
      " [31622400000000000 31536000000000000]\n",
      " [31536000000000000 31536000000000000]\n",
      " [31536000000000000 31536000000000000]\n",
      " [31536000000000000 31622400000000000]\n",
      " [31622400000000000 31536000000000000]\n",
      " [31536000000000000 31536000000000000]\n",
      " [31536000000000000 31536000000000000]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: Passing integers to fillna is deprecated, will raise a TypeError in a future version.  To retain the old behavior, pass pd.Timedelta(seconds=n) instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Timestamp' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-ca55851a8bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvert_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# invert differencing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverse_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;31m# store forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-1d552b38a312>\u001b[0m in \u001b[0;36minverse_difference\u001b[0;34m(history, yhat, interval)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# invert differenced value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minverse_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# scale train and test data to [-1, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/timestamps.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.__radd__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Timestamp' and 'float'"
     ]
    }
   ],
   "source": [
    "#data preprocessing to get LSTM working for player x\n",
    "#based on past yrs of player's performance, predict future performance  of player x)\n",
    "\n",
    "#cast all to same type float\n",
    "ozzie_Smith_DF['G'] = ozzie_Smith_DF['G'].astype(float)\n",
    "ozzie_Smith_DF['stint_ID'] = ozzie_Smith_DF['stint_ID'].astype(float)\n",
    "ozzie_Smith_DF = ozzie_Smith_DF.drop([\"team_ID\", \"lg_ID\", \"pitcher\", \"player_ID\", \"name_common\"], axis=1)\n",
    "ozzie_Smith_smallDF = ozzie_Smith_DF\n",
    "ozzie_Smith_smallDF = ozzie_Smith_smallDF.drop(['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg'], axis=1)\n",
    "\n",
    "print(ozzie_Smith_smallDF)\n",
    "# transform data to be stationary\n",
    "raw_values = ozzie_Smith_smallDF.values\n",
    "oneDim = np.stack(raw_values, axis =1)\n",
    "raw_values = oneDim[0]\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "print(\"supervised_values: \", len(supervised_values), supervised_values)\n",
    "train, test = supervised_values[0:-16], supervised_values[-16:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=1)\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "    # make one-step forecast\n",
    "    X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "    yhat = forecast_lstm(lstm_model, 1, X)\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    # invert differencing\n",
    "    yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "    expected = raw_values[len(train) + i + 1]\n",
    "    print('Year=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-16:], predictions))\n",
    "\n",
    "#print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-16:], label='WAR')\n",
    "pyplot.plot(predictions, label='Predicted War')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>90252</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90253</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90254</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90255</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90256</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90257</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90258</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90259</td>\n",
       "      <td>6.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90260</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90261</td>\n",
       "      <td>6.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90262</td>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90263</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90264</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90265</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90266</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90267</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90268</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90269</td>\n",
       "      <td>-0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90270</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WAR\n",
       "90252  3.25\n",
       "90253  1.64\n",
       "90254  5.07\n",
       "90255  0.99\n",
       "90256  5.03\n",
       "90257  3.78\n",
       "90258  4.98\n",
       "90259  6.42\n",
       "90260  5.58\n",
       "90261  6.43\n",
       "90262  6.60\n",
       "90263  7.30\n",
       "90264  3.62\n",
       "90265  5.06\n",
       "90266  5.10\n",
       "90267  3.11\n",
       "90268  2.10\n",
       "90269 -0.73\n",
       "90270  1.55"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ozzie_Smith_smallDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ozzie_Smith_smallDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised_values:  18 [[ 0.   -1.61]\n",
      " [-1.61  3.43]\n",
      " [ 3.43 -4.08]\n",
      " [-4.08  4.04]\n",
      " [ 4.04 -1.25]\n",
      " [-1.25  1.2 ]\n",
      " [ 1.2   1.44]\n",
      " [ 1.44 -0.84]\n",
      " [-0.84  0.85]\n",
      " [ 0.85  0.17]\n",
      " [ 0.17  0.7 ]\n",
      " [ 0.7  -3.68]\n",
      " [-3.68  1.44]\n",
      " [ 1.44  0.04]\n",
      " [ 0.04 -1.99]\n",
      " [-1.99 -1.01]\n",
      " [-1.01 -2.83]\n",
      " [-2.83  2.28]]\n",
      "Year=1, Predicted=4.088319, Expected=0.990000\n",
      "Year=2, Predicted=4.408757, Expected=5.030000\n",
      "Year=3, Predicted=5.052143, Expected=3.780000\n",
      "Year=4, Predicted=7.159815, Expected=4.980000\n",
      "Year=5, Predicted=3.989296, Expected=6.420000\n",
      "Year=6, Predicted=2.019613, Expected=5.580000\n",
      "Year=7, Predicted=7.757315, Expected=6.430000\n",
      "Year=8, Predicted=4.307412, Expected=6.600000\n",
      "Year=9, Predicted=3.251842, Expected=7.300000\n",
      "Year=10, Predicted=2.586241, Expected=3.620000\n",
      "Year=11, Predicted=8.283384, Expected=5.060000\n",
      "Year=12, Predicted=5.354102, Expected=5.100000\n",
      "Year=13, Predicted=3.259366, Expected=3.110000\n",
      "Year=14, Predicted=7.296619, Expected=2.100000\n",
      "Year=15, Predicted=4.483530, Expected=-0.730000\n",
      "Year=16, Predicted=2.598389, Expected=1.550000\n",
      "Test RMSE: 2.797\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data preprocessing to get LSTM working for player x\n",
    "#based on past yrs of player's performance, predict future performance  of player x)\n",
    "\n",
    "#cast all to same type float\n",
    "# ozzie_Smith_DF['G'] = ozzie_Smith_DF['G'].astype(float)\n",
    "# ozzie_Smith_DF['stint_ID'] = ozzie_Smith_DF['stint_ID'].astype(float)\n",
    "# ozzie_Smith_DF = ozzie_Smith_DF.drop([\"team_ID\", \"lg_ID\", \"pitcher\", \"player_ID\", \"name_common\"], axis=1)\n",
    "# ozzie_Smith_smallDF = ozzie_Smith_DF\n",
    "# ozzie_Smith_smallDF = ozzie_Smith_smallDF.drop(['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "#                                        'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "#                                        'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "#                                        'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "#                                         'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "#                                        'WAA', 'WAA_off', 'WAA_def', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "#                                        'salary', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "#                                        'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "#                                        'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg'], axis=1)\n",
    "\n",
    "# print(ozzie_Smith_smallDF)\n",
    "# # transform data to be stationary\n",
    "raw_values = ozzie_Smith_smallDF.values\n",
    "oneDim = np.stack(raw_values, axis =1)\n",
    "raw_values = oneDim[0]\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "\n",
    "print(\"supervised_values: \", len(supervised_values), supervised_values)\n",
    "train, test = supervised_values[0:-16], supervised_values[-16:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=1)\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "    # make one-step forecast\n",
    "    X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "    yhat = forecast_lstm(lstm_model, 1, X)\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    # invert differencing\n",
    "    yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "    expected = raw_values[len(train) + i + 1]\n",
    "    print('Year=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-16:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-16:], label='OPS_plus')\n",
    "pyplot.plot(predictions, label='Predicted OPS_plus')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised_values:  2091 [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " ...\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-b86e7a2a50a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# forecast the entire training dataset to build up state for forecasting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtrain_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-1d552b38a312>\u001b[0m in \u001b[0;36mfit_lstm\u001b[0;34m(train, batch_size, nb_epoch, neurons)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#data preprocessing to get LSTM working for player x\n",
    "#based on past yrs of player's performance, predict future performance  of player x)\n",
    "\n",
    "raw_values = frames.values\n",
    "oneDim = np.stack(raw_values, axis =1)\n",
    "raw_values = oneDim[0]\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "\n",
    "print(\"supervised_values: \", len(supervised_values), supervised_values)\n",
    "train, test = supervised_values[0:-16], supervised_values[-16:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=1)\n",
    "\n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "    # make one-step forecast\n",
    "    X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "    yhat = forecast_lstm(lstm_model, 1, X)\n",
    "    # invert scaling\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    # invert differencing\n",
    "    yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "    # store forecast\n",
    "    predictions.append(yhat)\n",
    "    expected = raw_values[len(train) + i + 1]\n",
    "    print('Year=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    "\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-16:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-16:], label='OPS_plus')\n",
    "pyplot.plot(predictions, label='Predicted OPS_plus')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM not serialized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np \n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Include players from 1975 and onward. Change pitcher indicator from Y/N to 1/0 for comparison reasons. Make dictionary mapping mlb ID to player name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players with years 2013 - 2017\n",
    "# just go through list of players that are  not pitchers \n",
    "\n",
    "batting_data_path = 'bsb_ref.csv'\n",
    "# INFO:\n",
    "# 101,332 Players with up to 49 features each (exluding year, including team)\n",
    "# if metric not reported for player, set to mean by default\n",
    "\n",
    "df = pd.read_csv(batting_data_path)\n",
    "df = df.fillna(df.mean()) # replace NA with the mean of the df\n",
    "df_recent_players = df[df.year_ID >= 1975] #only players after 1975\n",
    "\n",
    "\n",
    "#reorder columns so date is first\n",
    "#shape is (54579, 49)\n",
    "#Note rows are players and for each player years' worth of metrics hence the 54,579\n",
    "df_recent_players = df_recent_players[['year_ID', 'name_common', 'age', 'mlb_ID', 'player_ID', 'team_ID', 'stint_ID',\n",
    "                                       'lg_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'OPS_plus', 'TOB_lg', 'TB_lg']]\n",
    "\n",
    "#change Y/N to 1/0 for pitcher indicator\n",
    "pd.Series(np.where(df_recent_players.pitcher.values == 'Y', 1, 0),\n",
    "          df_recent_players.index)  \n",
    "\n",
    "\n",
    "#Dictionary mapping player's mlb ID to their name\n",
    "playerNameToID = {}\n",
    "for index, row in df_recent_players.iterrows():\n",
    "    playerNameToID[row['mlb_ID']] = row['name_common']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe of hitters only with data for years 2013 - 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_pitchers = df_recent_players[df_recent_players['pitcher'] != 1] #only players that aren't pitchers\n",
    "players = list(set(df_not_pitchers['name_common'])) # just a set of all players\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013 = pd.DataFrame(columns=df_not_pitchers.columns)\n",
    "df_2014 = pd.DataFrame(columns=df_not_pitchers.columns)\n",
    "df_2015 = pd.DataFrame(columns=df_not_pitchers.columns)\n",
    "df_2016 = pd.DataFrame(columns=df_not_pitchers.columns)\n",
    "df_2017 = pd.DataFrame(columns=df_not_pitchers.columns)\n",
    "for player in players:\n",
    "    rows_per_player = df_not_pitchers[df_not_pitchers['name_common'] == player]\n",
    "    if 2013 in rows_per_player.values and 2014 in rows_per_player.values and 2015 in rows_per_player.values and 2016 in rows_per_player.values and 2017 in rows_per_player.values:\n",
    "        df_2013 = df_2013.append(rows_per_player[rows_per_player['year_ID'] == 2013].head(1))\n",
    "        df_2014 = df_2014.append(rows_per_player[rows_per_player['year_ID'] == 2014].head(1))\n",
    "        df_2015 = df_2015.append(rows_per_player[rows_per_player['year_ID'] == 2015].head(1))\n",
    "        df_2016 = df_2016.append(rows_per_player[rows_per_player['year_ID'] == 2016].head(1))\n",
    "        df_2017 = df_2017.append(rows_per_player[rows_per_player['year_ID'] == 2017].head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removed 'name_common', 'player_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2013:  (523, 5)\n",
      "df_2017:  (523, 5)\n",
      "df_2013:  (523, 5)\n",
      "df_2017:  (523, 5)\n",
      "df_2017:  (523, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\ndf_2013:  (523, 46)\\ndf_2014:  (523, 46)\\ndf_2015:  (523, 46)\\ndf_2016:  (523, 46)\\ndf_2017:  (523, 49)\\n'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removed 'name_common', 'player_ID', OPS_plus\n",
    "\n",
    "y_2013 = df_2013[['OPS_plus']]\n",
    "y_2014 = df_2014[['OPS_plus']]\n",
    "y_2015 = df_2015[['OPS_plus']]\n",
    "y_2016 = df_2016[['OPS_plus']]\n",
    "opsPlusTest = df_2017[['OPS_plus']]\n",
    "\n",
    "df_2013 = df_2013[['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA']]\n",
    "df_2014 = df_2014[['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA']]\n",
    "\n",
    "df_2015 = df_2015[['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA']]\n",
    "df_2016 = df_2016[['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA']]\n",
    "\n",
    "df_2017 = df_2017[['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA']]\n",
    "\n",
    "print(\"df_2013: \", df_2013.shape)\n",
    "\n",
    "print(\"df_2017: \", df_2017.shape)\n",
    "print(\"df_2013: \", df_2014.shape)\n",
    "\n",
    "print(\"df_2017: \", df_2015.shape)\n",
    "print(\"df_2017: \", df_2016.shape)\n",
    "#print(\"frames: \", frames.shape)\n",
    "\n",
    "'''\n",
    "\n",
    "df_2013:  (523, 46)\n",
    "df_2014:  (523, 46)\n",
    "df_2015:  (523, 46)\n",
    "df_2016:  (523, 46)\n",
    "df_2017:  (523, 49)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2013:  (523, 44)\n",
      "df_2014:  (523, 44)\n",
      "df_2015:  (523, 44)\n",
      "df_2016:  (523, 44)\n",
      "df_2017:  (523, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\ndf_2013:  (523, 46)\\ndf_2014:  (523, 46)\\ndf_2015:  (523, 46)\\ndf_2016:  (523, 46)\\ndf_2017:  (523, 49)\\n'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removed 'name_common', 'player_ID', OPS_plus\n",
    "\n",
    "y_2013 = df_2013[['OPS_plus']]\n",
    "y_2014 = df_2014[['OPS_plus']]\n",
    "y_2015 = df_2015[['OPS_plus']]\n",
    "y_2016 = df_2016[['OPS_plus']]\n",
    "opsPlusTest = df_2017[['OPS_plus']]\n",
    "\n",
    "df_2013 = df_2013[['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'TOB_lg', 'TB_lg']]\n",
    "df_2014 = df_2014[['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'TOB_lg', 'TB_lg']]\n",
    "df_2015 = df_2015[['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'TOB_lg', 'TB_lg']]\n",
    "df_2016 = df_2016[['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'TOB_lg', 'TB_lg']]\n",
    "\n",
    "\n",
    "\n",
    "df_2017 = df_2017[['year_ID', 'age', 'mlb_ID', 'stint_ID',\n",
    "                                       'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', \n",
    "                                       'runs_infield', 'runs_outfield', 'runs_catcher', 'runs_good_plays',\n",
    "                                       'runs_defense', 'runs_position', 'runs_position_p', 'runs_replacement',\n",
    "                                        'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def',\n",
    "                                       'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep',\n",
    "                                       'salary', 'pitcher', 'teamRpG', 'oppRpG', 'oppRpPA_rep', 'oppRpG_rep',\n",
    "                                       'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off',\n",
    "                                       'waa_win_perc_def', 'waa_win_perc_rep', 'TOB_lg', 'TB_lg']]\n",
    "\n",
    "print(\"df_2013: \", df_2013.shape)\n",
    "print(\"df_2014: \", df_2014.shape)\n",
    "print(\"df_2015: \", df_2015.shape)\n",
    "print(\"df_2016: \", df_2016.shape)\n",
    "print(\"df_2017: \", df_2017.shape)\n",
    "#print(\"frames: \", frames.shape)\n",
    "\n",
    "'''\n",
    "\n",
    "df_2013:  (523, 46)\n",
    "df_2014:  (523, 46)\n",
    "df_2015:  (523, 46)\n",
    "df_2016:  (523, 46)\n",
    "df_2017:  (523, 49)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Billy Hamilton\n"
     ]
    }
   ],
   "source": [
    "print(playerNameToID[row['mlb_ID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c96b20128638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "result.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_ID</th>\n",
       "      <th>name_common</th>\n",
       "      <th>age</th>\n",
       "      <th>mlb_ID</th>\n",
       "      <th>player_ID</th>\n",
       "      <th>team_ID</th>\n",
       "      <th>stint_ID</th>\n",
       "      <th>lg_ID</th>\n",
       "      <th>PA</th>\n",
       "      <th>G</th>\n",
       "      <th>...</th>\n",
       "      <th>oppRpG_rep</th>\n",
       "      <th>pyth_exponent</th>\n",
       "      <th>pyth_exponent_rep</th>\n",
       "      <th>waa_win_perc</th>\n",
       "      <th>waa_win_perc_off</th>\n",
       "      <th>waa_win_perc_def</th>\n",
       "      <th>waa_win_perc_rep</th>\n",
       "      <th>OPS_plus</th>\n",
       "      <th>TOB_lg</th>\n",
       "      <th>TB_lg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2092.0</td>\n",
       "      <td>2092</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092</td>\n",
       "      <td>2092</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>2092</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "      <td>2092.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4.0</td>\n",
       "      <td>523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>524</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>Edwin Encarnacion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amarial01</td>\n",
       "      <td>BAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>523.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.239484</td>\n",
       "      <td>488133.189771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.758126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.177498</td>\n",
       "      <td>1.840767</td>\n",
       "      <td>1.835868</td>\n",
       "      <td>0.499820</td>\n",
       "      <td>0.499568</td>\n",
       "      <td>0.500722</td>\n",
       "      <td>0.491045</td>\n",
       "      <td>54.672973</td>\n",
       "      <td>69.050982</td>\n",
       "      <td>78.960871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.400215</td>\n",
       "      <td>61667.662888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.254719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194157</td>\n",
       "      <td>0.024275</td>\n",
       "      <td>0.023223</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>76.033069</td>\n",
       "      <td>79.515351</td>\n",
       "      <td>90.656224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>112526.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.854270</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>1.799000</td>\n",
       "      <td>0.417600</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.482900</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>452663.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.004552</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>1.816000</td>\n",
       "      <td>0.493275</td>\n",
       "      <td>0.494300</td>\n",
       "      <td>0.499402</td>\n",
       "      <td>0.485700</td>\n",
       "      <td>41.244725</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>488768.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.160190</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>1.837000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>56.623400</td>\n",
       "      <td>20.680000</td>\n",
       "      <td>24.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>520471.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.363282</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>1.862000</td>\n",
       "      <td>0.506200</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.501425</td>\n",
       "      <td>0.496100</td>\n",
       "      <td>103.620875</td>\n",
       "      <td>140.719500</td>\n",
       "      <td>160.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>624577.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>726.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.503060</td>\n",
       "      <td>2.058000</td>\n",
       "      <td>1.871000</td>\n",
       "      <td>0.793700</td>\n",
       "      <td>0.793700</td>\n",
       "      <td>0.541900</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>696.226600</td>\n",
       "      <td>243.739000</td>\n",
       "      <td>283.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year_ID        name_common          age         mlb_ID  player_ID  \\\n",
       "count    2092.0               2092  2092.000000    2092.000000       2092   \n",
       "unique      4.0                523          NaN            NaN        524   \n",
       "top      2016.0  Edwin Encarnacion          NaN            NaN  amarial01   \n",
       "freq      523.0                  4          NaN            NaN          4   \n",
       "mean        NaN                NaN    28.239484  488133.189771        NaN   \n",
       "std         NaN                NaN     3.400215   61667.662888        NaN   \n",
       "min         NaN                NaN    20.000000  112526.000000        NaN   \n",
       "25%         NaN                NaN    26.000000  452663.750000        NaN   \n",
       "50%         NaN                NaN    28.000000  488768.000000        NaN   \n",
       "75%         NaN                NaN    30.000000  520471.000000        NaN   \n",
       "max         NaN                NaN    43.000000  624577.000000        NaN   \n",
       "\n",
       "       team_ID  stint_ID lg_ID           PA       G     ...        oppRpG_rep  \\\n",
       "count     2092    2092.0  2092  2092.000000  2092.0     ...       2092.000000   \n",
       "unique      30       3.0     2          NaN   163.0     ...               NaN   \n",
       "top        BAL       1.0    AL          NaN     2.0     ...               NaN   \n",
       "freq        94    1996.0  1090          NaN   115.0     ...               NaN   \n",
       "mean       NaN       NaN   NaN   215.758126     NaN     ...          4.177498   \n",
       "std        NaN       NaN   NaN   247.254719     NaN     ...          0.194157   \n",
       "min        NaN       NaN   NaN     0.000000     NaN     ...          3.854270   \n",
       "25%        NaN       NaN   NaN     1.000000     NaN     ...          4.004552   \n",
       "50%        NaN       NaN   NaN    69.000000     NaN     ...          4.160190   \n",
       "75%        NaN       NaN   NaN   440.000000     NaN     ...          4.363282   \n",
       "max        NaN       NaN   NaN   726.000000     NaN     ...          4.503060   \n",
       "\n",
       "        pyth_exponent  pyth_exponent_rep  waa_win_perc  waa_win_perc_off  \\\n",
       "count     2092.000000        2092.000000   2092.000000       2092.000000   \n",
       "unique            NaN                NaN           NaN               NaN   \n",
       "top               NaN                NaN           NaN               NaN   \n",
       "freq              NaN                NaN           NaN               NaN   \n",
       "mean         1.840767           1.835868      0.499820          0.499568   \n",
       "std          0.024275           0.023223      0.016949          0.015717   \n",
       "min          1.790000           1.799000      0.417600          0.436000   \n",
       "25%          1.820000           1.816000      0.493275          0.494300   \n",
       "50%          1.840000           1.837000      0.500000          0.500000   \n",
       "75%          1.865000           1.862000      0.506200          0.505200   \n",
       "max          2.058000           1.871000      0.793700          0.793700   \n",
       "\n",
       "        waa_win_perc_def  waa_win_perc_rep     OPS_plus       TOB_lg  \\\n",
       "count        2092.000000       2092.000000  2092.000000  2092.000000   \n",
       "unique               NaN               NaN          NaN          NaN   \n",
       "top                  NaN               NaN          NaN          NaN   \n",
       "freq                 NaN               NaN          NaN          NaN   \n",
       "mean            0.500722          0.491045    54.672973    69.050982   \n",
       "std             0.006991          0.005839    76.033069    79.515351   \n",
       "min             0.463700          0.482900  -100.000000     0.000000   \n",
       "25%             0.499402          0.485700    41.244725     0.325000   \n",
       "50%             0.500000          0.490500    56.623400    20.680000   \n",
       "75%             0.501425          0.496100   103.620875   140.719500   \n",
       "max             0.541900          0.500000   696.226600   243.739000   \n",
       "\n",
       "              TB_lg  \n",
       "count   2092.000000  \n",
       "unique          NaN  \n",
       "top             NaN  \n",
       "freq            NaN  \n",
       "mean      78.960871  \n",
       "std       90.656224  \n",
       "min        0.000000  \n",
       "25%        0.414000  \n",
       "50%       24.667500  \n",
       "75%      160.669500  \n",
       "max      283.620000  \n",
       "\n",
       "[11 rows x 49 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import zeros, newaxis\n",
    "# allSamples = []\n",
    "# y_list = []\n",
    "# for index, row in frames.iterrows():\n",
    "#     allSamples.append(row[['mlb_ID', 'stint_ID', 'PA', 'G', 'Inn', 'runs_bat', 'runs_br', 'runs_dp', 'runs_field', 'runs_infield', \n",
    "#                            'runs_outfield', 'runs_catcher', 'runs_good_plays', 'runs_defense', 'runs_position', 'runs_position_p', \n",
    "#                            'runs_replacement', 'runs_above_rep', 'runs_above_avg', 'runs_above_avg_off', 'runs_above_avg_def', \n",
    "#                            'WAA', 'WAA_off', 'WAA_def', 'WAR', 'WAR_def', 'WAR_off', 'WAR_rep', 'teamRpG', 'oppRpG', 'oppRpPA_rep', \n",
    "#                            'oppRpG_rep', 'pyth_exponent', 'pyth_exponent_rep', 'waa_win_perc', 'waa_win_perc_off', 'waa_win_perc_def', \n",
    "#                            'waa_win_perc_rep', 'TOB_lg', 'TB_lg']].values)\n",
    "# #     y_list.append(row[['OPS_plus']].values)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2017 32.0 571666.0 1 1.0]\n",
      " [2017 33.0 488912.0 1 31.0]\n",
      " [2017 32.0 430912.0 1 34.0]\n",
      " ...\n",
      " [2017 30.0 476451.0 2 158.07315681137726]\n",
      " [2017 28.0 594809.0 1 107.0]\n",
      " [2017 26.0 571740.0 1 633.0]]\n",
      "Single year shape =  (523, 5)\n",
      "Single year shape =  (523, 5)\n",
      "Single year shape =  (523, 5)\n",
      "Single year shape =  (523, 5)\n",
      "Single year shape =  (523, 5)\n"
     ]
    }
   ],
   "source": [
    "# players = df_2013.name_common.values\n",
    "years = [2013, 2014, 2015, 2016, 2017]\n",
    "\n",
    "print(df_2017.values)\n",
    "players_2013 = df_2013.to_numpy()\n",
    "players_2014 = df_2014.to_numpy()\n",
    "players_2015 = df_2015.to_numpy()\n",
    "players_2016 = df_2016.to_numpy()\n",
    "players_2017 = df_2017.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "print('Single year shape = ', players_2013.shape)\n",
    "print('Single year shape = ', players_2014.shape)\n",
    "print('Single year shape = ', players_2015.shape)\n",
    "print('Single year shape = ', players_2016.shape)\n",
    "print('Single year shape = ', players_2017.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(523, 4, 5)\n",
      "(523, 1)\n",
      "(523, 1)\n",
      "(523, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "# players_2013.shape\n",
    "\n",
    "train = np.stack([players_2013], axis=1)\n",
    "# train = np.stack([players_2013, players_2014, players_2015, players_2016], axis=1)\n",
    "\n",
    "test = np.stack([players_2017], axis=1)\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "print(y_2013.shape)\n",
    "print(y_2014.shape)\n",
    "\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-5a605ce6643e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplayers_2013\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayers_2014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayers_2015\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayers_2016\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Single year shape = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayers_2013\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All years shape = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "players = np.stack([players_2013, players_2014, players_2015, players_2016], axis=1)\n",
    "print('Single year shape = ', players_2013.shape)\n",
    "print('All years shape = ', players.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_56 (LSTM)               (None, 64)                17920     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,985\n",
      "Trainable params: 17,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(1, 5)))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 523 samples, validate on 523 samples\n",
      "Epoch 1/20\n",
      "523/523 [==============================] - 2s 5ms/step - loss: 8470.1688 - val_loss: 8622.9084\n",
      "Epoch 2/20\n",
      "523/523 [==============================] - 0s 191us/step - loss: 8446.7922 - val_loss: 8598.9958\n",
      "Epoch 3/20\n",
      "523/523 [==============================] - 0s 174us/step - loss: 8424.3640 - val_loss: 8574.5388\n",
      "Epoch 4/20\n",
      "523/523 [==============================] - 0s 172us/step - loss: 8400.5089 - val_loss: 8551.2347\n",
      "Epoch 5/20\n",
      "523/523 [==============================] - 0s 176us/step - loss: 8378.5107 - val_loss: 8526.7157\n",
      "Epoch 6/20\n",
      "523/523 [==============================] - 0s 163us/step - loss: 8355.5426 - val_loss: 8503.5788\n",
      "Epoch 7/20\n",
      "523/523 [==============================] - 0s 182us/step - loss: 8333.3078 - val_loss: 8480.6100\n",
      "Epoch 8/20\n",
      "523/523 [==============================] - 0s 173us/step - loss: 8311.0945 - val_loss: 8457.4296\n",
      "Epoch 9/20\n",
      "523/523 [==============================] - 0s 164us/step - loss: 8288.4115 - val_loss: 8433.9880\n",
      "Epoch 10/20\n",
      "523/523 [==============================] - 0s 176us/step - loss: 8265.9432 - val_loss: 8410.2547\n",
      "Epoch 11/20\n",
      "523/523 [==============================] - 0s 177us/step - loss: 8243.5980 - val_loss: 8386.8391\n",
      "Epoch 12/20\n",
      "523/523 [==============================] - 0s 164us/step - loss: 8221.7198 - val_loss: 8363.6590\n",
      "Epoch 13/20\n",
      "523/523 [==============================] - 0s 201us/step - loss: 8200.0874 - val_loss: 8341.3468\n",
      "Epoch 14/20\n",
      "523/523 [==============================] - 0s 194us/step - loss: 8178.5543 - val_loss: 8318.5596\n",
      "Epoch 15/20\n",
      "523/523 [==============================] - 0s 182us/step - loss: 8157.5390 - val_loss: 8296.0558\n",
      "Epoch 16/20\n",
      "523/523 [==============================] - 0s 202us/step - loss: 8136.1310 - val_loss: 8274.1419\n",
      "Epoch 17/20\n",
      "523/523 [==============================] - 0s 197us/step - loss: 8115.3400 - val_loss: 8252.2133\n",
      "Epoch 18/20\n",
      "523/523 [==============================] - 0s 187us/step - loss: 8094.1565 - val_loss: 8230.6456\n",
      "Epoch 19/20\n",
      "523/523 [==============================] - 0s 206us/step - loss: 8073.7282 - val_loss: 8208.6476\n",
      "Epoch 20/20\n",
      "523/523 [==============================] - 0s 197us/step - loss: 8052.5391 - val_loss: 8187.6675\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "lstm_history = model.fit(train, y_2013, epochs=20, validation_data=(test, y_2017), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
